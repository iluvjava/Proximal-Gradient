\documentclass[]{article}
\usepackage{amsmath}
\usepackage{amsfonts} 
\usepackage[english]{babel}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{algorithmic}
\usepackage{algorithm}
% \usepackage{minted}
% Basic Type Settings ----------------------------------------------------------
\usepackage[margin=1in,footskip=0.25in]{geometry}
\linespread{1}  % double spaced or single spaced
\usepackage[fontsize=12pt]{fontsize}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}       % Theorem counter global 
\newtheorem{prop}{Proposition}[section]  % proposition counter is section
\newtheorem{lemma}{Lemma}[subsection]  % lemma counter is subsection
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}[subsection]
{
    % \theoremstyle{plain}
    \newtheorem{assumption}{Assumption}
}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}
\usepackage[final]{graphicx}
\usepackage{listings}
\usepackage{courier}
\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}
\newcommand{\indep}{\perp \!\!\! \perp}
\usepackage{wrapfig}
\graphicspath{{.}}
\usepackage{fancyvrb}

%%
%% Julia definition (c) 2014 Jubobs
%%
\usepackage[T1]{fontenc}
\usepackage{beramono}
\usepackage[usenames,dvipsnames]{xcolor}
\lstdefinelanguage{Julia}%
  {morekeywords={abstract,break,case,catch,const,continue,do,else,elseif,%
      end,export,false,for,function,immutable,import,importall,if,in,%
      macro,module,otherwise,quote,return,switch,true,try,type,typealias,%
      using,while},%
   sensitive=true,%
   alsoother={$},%
   morecomment=[l]\#,%
   morecomment=[n]{\#=}{=\#},%
   morestring=[s]{"}{"},%
   morestring=[m]{'}{'},%
}[keywords,comments,strings]%
\lstset{%
    language         = Julia,
    basicstyle       = \ttfamily,
    keywordstyle     = \bfseries\color{blue},
    stringstyle      = \color{magenta},
    commentstyle     = \color{ForestGreen},
    showstringspaces = false,
}

\begin{document}


\title{Proximal Gradient: Convergence, Implementations and Applications}
\maketitle
\begin{abstract}
    We prove the proximal gradient and accelerated proximal gradient algorithm convergence rate under convexity assumptions. The proof for proximal gradient wihtout the Nesterov Acceleration is done differently compare to the original by work by Beck\cite{paper:FISTA}, we extract out a lemma and then use it to prove the convergence rate under the accelerated case. Additionally, we provide thorough context for the proximal gradient method by incorperating the majorization via envelope idea. Finally, we make numerical experiment that is different from Beck's original work by keeping track of the norm of the fixed point error on the proximal gradient step during our numerical experiment to expose a 2 phase descent property. 
\end{abstract}

\numberwithin{equation}{subsection}
\section{Introduction}
    We are concerned with the problem type: 
    \begin{align}
        \min_{x} g(x) + h(x),
    \end{align}
    where the objectives can be splitted into the sum of two functions. Algorithms are developed for solving optimization problems of this format. We will list some of the algorithms with their convergence rate under different assumptions. 
    \begin{enumerate}
        \item [1.] The projected subgradient algorithm solves $h = \delta_Q$ where $Q$ is a closed convex set and $g$ is closed and convex with $Q\subseteq\text{ri}\circ \text{dom}(g)$. The algorithm generates a sequence of $x^{(k)}$ where the weighted average of the sequence by step size has a convergence rate of $\mathcal O(1/\sqrt{k})$ in terms of the optimality; this result is from the convex analysis class I took before. For a more throughly exposition of the matter regarding the convergence of the optimality for subgradient method under the choice of Polyak Step Size, refer to Theorem 8.13 of Beck's work\cite{book:first_order_opt}. 
        \item [2.] The proximal Graidient algorithm are used for strongly smooth function $g$ and a convex, closed and proper function $h$ that has an easy to compute proximal oracle. Under convexity assumption for $h$, the optimal and the minimizer exists and the convergence rate is $\mathcal O(1/k)$. We will proe this results in our report. 
        \item [3.] The Accelerated Proximal Algorithm, which is a modified version of the proximal gradient that uses Nesterov Momentum and converges with $\mathcal O(1/k^2)$ with an additional convexity assumption on $g$. The convergence can be even faster when more additional assumptions are added to $g$. We will prove the convergence results under convexity assumption in this report as well.  
    \end{enumerate}
    In this report, we introduce the setup for the proximal gradient algorithms. We give proofs for the convergence results of the Proximal Gradient algorithms with fixed step sizes with and without the Nestrov Momentum. Finally, we also implemented some nontrivial examples of the algorihm in Julia. The code produces the plots for the numerical experiments can be found on my github \href{https://github.com/iluvjava/Proximal-Gradient}{here}. 
    \par
    For this report, most of the content can be found in Amir's Beck and textbook \cite{book:first_order_opt}, and the proof for the convergence of Accelerated Proximal Gradient method closely follows the original paper for FISTA\cite{paper:FISTA} by Amir and Marc Teboulle. Other additional and specific materials might get used during the expression as well. 
    \par 
    In the \hyperref[sec:preliminaries]{section \ref*{sec:preliminaries}} we introduce the minimum mathematical background needed to understand the proximal gradient method. In the second \hyperref[sec:pg_forward_backward_env]{section \ref*{sec:pg_forward_backward_env}} we introduce the proximal gradient via envelope and the idea of majorization and minimization. In addition, we introduce several important lemma related to the monotone property of the Proximal Gradient method and the choice of step size, and extract out the important \hyperref[lemma:prox_two_p]{lemma \ref*{lemma:prox_two_p}} for the proof of the accelerated case, which is in the appendix. In \hyperref[sec:pg_convergence]{section \ref*{sec:pg_convergence}} we prove the convergence of the proximal gradient method under convexity and smoothness assumption with a fixed step size. And in section \ref*{sec:apg_intro} we state the proximal gradient algorithm with Nesterov acceleration (also refers to as FISTA), and in the appendix we prove the better cnvergence of FISTA in thorough detail. Finally, for applications in \hyperref[sec:numerical_experiments]{section \ref*{sec:numerical_experiments}}, we consider the convergence of the optimality and the norm of the gradient mapping for the LASSO problem, and then we apply the LASSO algorithm for the task of deblurring images with high gussian noise. In the that same section, other common applications and extension of the algorithm will also be introduced. 
    \subsection{Contribution of the Literatures}
        The proximal gradient method exists, Beck's contribution to the matter is the use of Nesterov Acceleration term that improves the convergence rate with a proof. Beck popularized the use of momentum in a wider context to improve convergence of algorithms. 
\section{Preliminaries}\label{sec:preliminaries}
    The proximal operator is a crucial component for the algorithm and its non-expansive  property is relevant to the convergence of Proximal Gradient under the non-convex case. We won't go into detail for the non-convex case. Under the assumption of convexity for $f$, the property of the strongly smooth function is more relevant. 
    \subsection{The Proximal Operator}
        \begin{definition}[Proximal Operator and Moreau Envelope]
            A Moreau Envelope $\text{env}_{\alpha, f}(x)$, $\text{prox}_{\alpha, f}$ the proximal operator are defined for some function $f$: 
            $$
            \begin{aligned}
                & \text{env}_{f, \alpha}(x) := \min_{y}\left\lbrace
                    f(y) + \frac{1}{2 \alpha }\Vert y - x\Vert^2
                \right\rbrace, 
                \\
                & \text{prox}_{f, \alpha}(x) := 
                \arg\min_{y}\left\lbrace
                    f(y) + \frac{1}{2\alpha} \Vert y - x\Vert^2
                \right\rbrace. 
            \end{aligned}
            $$
        \end{definition}
        
        The proximal operator is a singleton when the function $f$ is convex, proper and closed due to the strong convexity of $f(y) + 1/(2\alpha)\Vert y - x\Vert^2$. Observe that $\text{env}_{\alpha, f}(x) = (f\square \frac{1}{2\alpha}\Vert \cdot \Vert^2)(x)$, hence the infimal convolution gives us the interpretation that the epigraphs of the envelope is adding between the epigraph of these 2 functions. This conceptualization will help with the intuitive understanding of many proximal algorithm. 
        In addition please observe the following identities: 

        $$
        \begin{aligned}
            & \text{prox}_{f/\alpha, 1} =  \text{prox}_{f, \alpha}
            \\
            & \alpha^{-1}\text{env}_{\alpha f, 1}(x) = \text{env}_{f, \alpha}(x). 
        \end{aligned}
        $$
        \begin{prop}[Proximal Operator is a Nonexpansive Mapping]
            Let $f:\mathbb E \mapsto \mathbb{\bar R}$ be a closed, convex proper function. then $\text{prox}_f(x)$, with $\alpha= 1$ is a singleton for every point $x\in \mathbb E$. Moreoever, for any points $x, y\in \mathbb E$ the estimate holds: 
            $$
                \begin{aligned}
                    \Vert \text{prox}_f(x) - \text{prox}_f(y)\Vert^2_\star \le 
                    \langle \text{prox}_f(x) - \text{prox}_f(y), x - y\rangle. 
                \end{aligned}
            $$
        \end{prop}
        Using the identity that $\text{prox}_{f/\alpha} = \text{prox}_{f, \alpha}$, the proximal gradient is nonexpansive for all value of $\alpha$. 
        \begin{lemma}[Proximal Operator as Resolvant of Scaled Subgradient]\label{lemma:prox_alternative_form}
            When the function $f$ is convex closed and proper, the $\text{prox}_{\alpha, f}$ can be viewed the following operator $(I + \alpha \partial f)^{-1}$, which is also, a single valued operator that sometimes has a nice closed form solution to it.
        \end{lemma}
        \begin{proof}
            \begin{align*}
                0 &\in \partial\left[
                    \left.
                        f(y) + \frac{1}{2\alpha} \Vert y - x\Vert^2 
                    \right| y
                \right](y^+)
                \\
                0 &\in \partial f(y^+) + \frac{1}{\alpha}(y^+ - x)
                \\
                \frac{x}{\alpha} &\in 
                (\partial f + \alpha^{-1}I)(y^+)
                \\
                x &\in 
                (\alpha \partial f + I)(y^+)
                \\
                y &\in (\alpha\partial f+ I)^{-1}(x).
            \end{align*}
        \end{proof}
    \subsection{The Strong Smoothness}
        \begin{definition}[Strong Smoothness]\label{def:strong_smoothness}
            A differentiable function $g$ is called smooth with a constant $\alpha$ then it satisfies: 
            \begin{align}
                |g(y) - g(x) - 
                \langle \nabla g(x), y - x
                \rangle| \le \frac{\alpha}{2}\Vert x - y\Vert^2
                \quad \forall x, y\in \mathbb E. 
            \end{align}    
        \end{definition}
        The absolute value sign can be removed and replaced with $0\le$ when the function $g$ is a convex function.
        \begin{theorem}[Lipschiz Gradient and Strong Smoothness Equivalence Under Convexit]\label{thm:cvx_lipz_grad}
            If $g$ is differentiable on the entire of $\mathbb E$, it's closed convex proper and it's strongly smooth with parameter $\alpha$, if and only if the gradient $\nabla g$ is gobally Lipschiz continuous with a parameter of $\alpha$ and $g$ is closed and convex. 
        \end{theorem}
        \begin{proof}
            For conciseness we skip the proof here, to convince, consider applying generalized Cauchy Inequality to item (iv) in Theorem 5.8 for Beck's textbook \cite{paper:FISTA}. 
        \end{proof}
        
\section{Proximal Gradient and Forward Backward Envelope}\label{sec:pg_forward_backward_env}
    We introduce the algorithm through the forward backward envelope, this helps with the intuitive undestanding with this algorithm. We then state some of the important properties. The name forward backward envelope is credit to numerical method that simulates gradient dynamical system that is the summation of a stiff and nonstiff dynamics by using forward Euler on the nonstiff part, and backward Euler on the stiff part. We won't go into detail regarding this specific interpretation of the proximal gradient method. For more detail regarding this interpretation of proximal gradient method refers to Bloyd's paper \cite{paper:bloyd}. 
    \begin{assumption}[Convex Smooth Nonsmooth with Bounded Minimizers]\label{assumption:1}
        We will assume that $g:\mathbb E\mapsto \mathbb R$ is strongly smooth with constant $L_g$ and $h:\mathbb E \mapsto \bar{\mathbb R}$ is closed convex and proper. We define $f := g + h$ to be the summed function and $\text{ri}\circ \text{dom}(g) \cap \text{ri}\circ \text{dom}(h) \neq \emptyset$. We also assume that there exists a set of minimizers for the function $f$ and the set is bounded and any one of the element from the set will be denoted using $\bar x$. 
    \end{assumption}
    
    \subsection{Proximal Gradient Minimizes the Forward Backward Envelope}
        First, we follow the intuitive idea of constructing a upper bounding function given a parameter $\beta$ as  $m_x(y|\beta)$, it can be interpreted as a surrogate function if one prefers for $g + h$ with $\beta \ge L_g$: 
        \begin{align*}
            & g(x) + h(x) \le 
            g(x) + \nabla g(x)^T(y - x) + \frac{\beta}{2} \Vert y - x\Vert^2
            + h(y) =: m_x(y|\beta) \quad \forall y \in \mathbb E, 
        \end{align*}
        this function $m_x(y|\beta)$ is a strongly convex function and it's equal to $g + h$ at $x$, and larger than it on every other points. The \emph{envelope function}, defined as $m^+(y|\beta):= \min_y \{m_x(y|\beta)\}$ minimizes the upper bounding function, and the function $m^+$ is lower than $g + h$ on all points and its minimizer takes the following form: 
        \begin{align*}
            \arg\min_{y} \{m_x(y)\} 
            = \arg\min_{y}\left\lbrace
                g(x) + \nabla g(x)^T(y - x) + \frac{\beta}{2}
                \Vert y - x\Vert^2 + h(y) 
            \right\rbrace. 
        \end{align*}
        
        \begin{theorem}[Minimizer of the Envelope]\label{thm:minimizer_envelope}
            The minimizer for the envelope has a closed form and it's $\text{prox}_{h, \beta^{-1}}(x + \beta^{-1}\nabla g(x))$, with \hyperref[assumption:1]{assumption \ref*{assumption:1}}. 
        \end{theorem}
        \begin{proof}
            We consider the fact that, to minimize the envelope, zero is in the subgradient of the upper bounding function $m_x(y|\beta)$. 
            \begin{align*}
                \mathbf 0 &\in 
                \nabla g(x) + {\beta}(y - x) + \partial h(y)
                \\
                \nabla g(x) + \beta x & \in
                \beta y + \partial h(y)
                \\
                -\beta^{-1} \nabla g(x) + x &\in y + \beta^{-1} \partial h(y)
                \\
                -\beta^{-1} \nabla g(x) + x &\in [I + \beta^{-1} \partial h](y)
                \\
                \implies
                [I + \beta^{-1}\partial h]^{-1}(- \beta^{-1} \nabla g(x) + x) 
                & \ni y,
            \end{align*}
            using \hyperref[lemma:prox_alternative_form]{lemma \ref*{lemma:prox_alternative_form}}, the RHS is the operator $\text{prox}_{h, \beta^{-1}}(x + \beta^{-1}\nabla g(x))$. 
        \end{proof}
        \begin{remark}
            The minimizer of the envelope at $x$: $\text{prox}_{h, \beta^{-1}}(x + \beta^{-1}\nabla g(x))$ is what we call \emph{prox step} for short, it makes the envelope $m_x(y|\beta)$ strictly lower than $f(x)$ for any point $x$ that is not the minimizer of $h + g$. 
        \end{remark}
    \subsection{Fixed Point of the Prox Step}\label{sec:fixed_point_prox}
        Denote the prox step $\mathcal P_{\beta^{-1}}^{g, h}(x) = \text{prox}_{h, \beta^{-1}}(x - \beta^{-1}\nabla g(x))$, in most context without ambiguity it will be simply denoted as $\mathcal Px$. The fixed point of $\mathcal P$ is a point $x$ such that $x = \mathcal P x$ if and only if $x$ is the minimizer of $f$ when \hyperref[assumption:1]{assumption \ref*{assumption:1}} is true. We denoted the fixed point as $\bar x$. To see how this is true consider any $x^+$ such that $x^+ = \mathcal Px$, using subgradient of the envelope: 
        \begin{align*}
            \mathbf 0 
            &\in \nabla g(x) + \beta(x^+ - x) + \partial h(x^+)
            \\
            \beta(x - x^+) &\in \partial h(x^+) + \nabla g(x^+)
            \\
            x = x^+ \iff \mathbf 0 &\in 
            \partial h(x^+) + \nabla g(x^+), 
        \end{align*}
        and therefore, if $x^+$ is fixed point of $\mathcal P$ if and only if it is one of the local minimizers of the function $f$. Conversely, if $x^+$ is not a fixed point of $x$, then it has to make the objective value of the upper bounding function $m_x(y| \beta)$ decreases because it's a strongly convex function. However, this doesn't necessarily mean that the prox step can decrease the value of the function $f$, more conditions are needed for the parameter $\beta$ to bound the value $f$ at the prox step point. We explain more about this in the next subsection. 
        \begin{remark}
            The operator $\beta(x - \mathcal Px)$ is called the gradient mapping in Amiar's Book \cite{book:first_order_opt}, and it has many more important properties that are useful for the convergence proof of proximal gradient method under many different context. Please observe that, if the function $h \equiv 0$, the gradient mapping is simply the gradient of the function $g$. We won't go into the details here unfortunately cause that is outside of the scope. 
        \end{remark}
    \subsection{Step-Sizes that Ensures Monotone Descent Property}
        With \hyperref[assumption:1]{assumption \ref*{assumption:1}}, only a specific size of step-size can guarantee a decrease in the function value for the minimizers that minimizes the envelope. For this section we denote. 
        \begin{theorem}[Stepsize that Ensures Monotone Decrease]\label{thm:monotone_decrease}
            The step size $L^{-1}$ of the proximal gradient that guarantee a decrease in the objective value has to satisfies: $L \ge L_g$, where $L_g$ is the lipschitz constant for the gradient of the function $g$ (recall \hyperref[thm:cvx_lipz_grad]{theorem \ref*{thm:cvx_lipz_grad}}) and $\mathcal Px$ is $\mathcal P_{L^{-1}}^{g, h}(x)$. 
        \end{theorem}
        \begin{proof}Consider the fact that the envelope at the prox step is smaller than the point where the envelope is touching with the function $f$ at $x$ (recall \hyperref[thm:minimizer_envelope]{theorem \ref*{thm:minimizer_envelope}}), we have $m_x(\mathcal Px|L_f)\le f(x)$ which gives: 
            \begin{align*}
                m_x(\mathcal Px|L) \le m_x(\mathcal Px|L_f) 
                &\le f(x)
                \\
                \implies h(\mathcal Px)+ 
                \langle \nabla g(x), \mathcal P x - x\rangle + \frac{L}{2}\Vert \mathcal Px - x\Vert^2 
                &\le h(x)
                \\
                h(\mathcal Px) - h(x) + \langle \nabla g(x) - \mathcal Px - x\rangle 
                &\le \frac{-L}{2} \Vert \mathcal Px - x\Vert^2, \tag{$\Delta$}
            \end{align*}
            next we also consider the strongly smooth property of $g$ to obtain: 
            \begin{align*}
                g(\mathcal Px) - g(x) - \langle \nabla g(x), \mathcal Px - x\rangle 
                & \le \frac{L_g}{2}\Vert \mathcal Px - x\Vert^2 \tag{$\nabla$}
                \\
                \implies
                h(\mathcal Px) + g(\mathcal Px) - g(x) - h(x)
                &\le 
                \left(
                    \frac{L_g}{2} - \frac{L}{2}
                \right)\Vert \mathcal Px - x\Vert^2 \tag{**}
                \\
                f(\mathcal Px) - f(x) 
                &\le
                \left(
                    \frac{L_g}{2} - \frac{L}{2}
                \right)\Vert \mathcal Px - x\Vert^2, 
            \end{align*}
            where (**) is $(\nabla) + (\Delta)$. Observe that on the last line, if $L_g \le L$, then the objective decrease is asserted. Additionally, using \hyperref[thm:minimizer_envelope]{theorem \ref*{thm:minimizer_envelope}}, we have $L^{-1}$ being the step sizes inside of the proximal gradient operator. See Beck's paper \cite{paper:FISTA} for more details about line search conditions employed for the proximal gradient algorithm.
        \end{proof}
        \begin{remark}
            The monotone decrease property of a step size is useful for engineering the back tracking routine for the proximal gradient method. More specifically, as long as the step size $L^{-1}$ satisfies $m_x(\mathcal Px | L)\le f(x)$, then it's an acceptabled step size. 
        \end{remark}
    \subsection{Proximal Gradient Algorithm}
        \begin{algorithm}[H]
            \begin{algorithmic}[1]
            \STATE{\textbf{Input:} $g, h$, smooth and nonsmooth, $L$ stepsize, $x^{(0)}$ an initial guess of solution. }
            \FOR{$k=1, 2,\cdots, N$}
                \STATE{\quad $x^{(k + 1)} = \mathcal P_L^{g, h}x^{(k)}$}
                \IF{$x^{(k + 1)}, x^{(k)}$ close enough}
                    \STATE{\textbf{Break}}
                \ENDIF
            \ENDFOR
            \end{algorithmic}
            \caption{Proximal Gradient With Fixed Step-sizes}
            \label{alg:1}
        \end{algorithm}
        \begin{remark}
            The \hyperref[alg:1]{Proximal Gradient With Fixed Step Size} algorithm terminates either the iteration limit $N$ is reached, or the fixed point iterations on the operator $\mathcal P$ has converged. Under some cases, the Lipschiz constant for $g$ can be obtained, under some other cases it's not easy to obtain. 
        \end{remark}

\section{Convergence of Proximal Gradient}\label{sec:pg_convergence}
    Here, we give analysis for the convergence behaviors of the algorithm in \hyperref[alg:1]{\ref*{alg:1}} with fixed stepsizes and assumption \hyperref[assumption:1]{\ref*{assumption:1}} is true. 
    \subsection{Convergence Under the Convex Case}
        Before the proof, we state some of the quantities that are involved in the proof. 
        \begin{enumerate}
            \item [1.] Recall from \hyperref[sec:fixed_point_prox]{section \ref*{sec:fixed_point_prox}} where $G_\beta(x) - \nabla g(x) \in \partial h(x^+)$ with $x^+ \in \mathcal P_{\beta^{-1}}^{g, h}(x)$, and this general condition is true for all values of $x$. We refers $G_\beta(x)$ as the residual of the proximal gradient algorithm. Finally, $G_\beta(x) = \beta(x - x^+)$
            \item [2.] By choosing the stepsize $\beta^{-1} \le L^{-1}$, we assert strict decrease of the value of the objective function, $f(x^+) \le f(x)$. 
            \item [3.] We denote $\bar f$ to be $f(\bar x)$ where $\bar x$ is one of the minimizer of $f$. 
        \end{enumerate}
        \begin{theorem}[Convergence Under Convexity]\label{thm:convergence_non_accelerated}
            With \hyperref[assumption:1]{assumption \ref*{assumption:1}}, execute the algorithm for $N$ steps, we have: 
            \begin{align*}
                f(x^{(N + 1)}) - \bar f
                &\le  
                \frac{\beta(\Vert x^{(0)} - \bar x\Vert^2 - \Vert x^{(N + 1)} - \bar x\Vert^2)}{2(N + 1)}. 
            \end{align*}
        \end{theorem}
        \begin{proof}
            This proof is standard and doesn't completely resemble the proof showed in \cite[Aimir, Teboulle]{paper:FISTA}, nonetheless we will extract a lemma out of this proof and use that as the foundation for the proof in the Nesterov Accelerated case of the proximal gradient algorithm.  
            \par
            Firstly by the choice of step-size and the strong smoothness of the function $g$, we have the inequality: 
            \begin{align*}
                g(x^+) 
                & \le 
                g(x) - \beta^{-1}\langle \nabla g(x), G_\beta(x)\rangle + \underbrace{\frac{L}{2\beta^2}\Vert G_\beta(x)\Vert^2}_
                {
                    \le \frac{1}{2\beta}\Vert G_\beta(x)\Vert^2
                }, \tag{*}
            \end{align*}
            next, by the convexity of $f, g$ we have inequalities: 
            \begin{align*}
                & g(x) \le g(z) - \langle \nabla g(x), x - z\rangle
                \\
                & h(x^+)\le h(z) + \langle \partial h(x^+), x^+ - z\rangle, 
            \end{align*}
            where we abuse the notation $\partial h(x^+)$ to denote some vector in the subgradient of $h$ at point $x^+$. Next we substitue the above results to into (*): 
            \begin{align*}
                g(x^+) + h(x^+) 
                & \le 
                g(x) + \beta^{-1}\langle \nabla g(x), G_\beta(x)\rangle + \frac{1}{2\beta}\Vert G_\beta(x)\Vert^2 + h(x^+) 
                \\
                & \le 
                g(z) + 
                \underbrace{\langle \nabla g(x), x - z\rangle }_{[1]}
                - 
                \underbrace{\beta^{-1}\langle \nabla g(x), G_\beta(x)\rangle}_{[2]}
                \\& \quad \quad 
                + 
                \frac{1}{2\beta}\Vert G_\beta(x)\Vert^2 + h(z) + 
                \underbrace{\langle \partial h(x^+), x^+ - z\rangle}_{[4]}, 
                \tag{$\nabla$}
            \end{align*}
            and we consider the summation for each of these numerically labeled term to obtain: 
            \begin{align*}
                {[3]}& := [1] + [2]
                \\
                [3] &= \langle \nabla g(x), x - z - x + x^+\rangle = \langle \nabla g(x), x^+ - z\rangle
                \\
                [3] + [4] &= 
                \langle \nabla g(x), x^+ - z\rangle + \langle G_\beta(x) - \nabla g(x), x^+ - z\rangle \tag{**}
                \\
                &= \langle G_\beta(x), x^+ - z\rangle 
                \\
                &= \langle G_\beta(x), x - z - (x - x^+)\rangle
                \\
                &= \langle G_\beta, x - z\rangle - \langle G_\beta, \underbrace{x - x^+}_{ = \beta^{-1}G_\beta(x)}\rangle
                \\
                &= \langle G_\beta(x), x - z\rangle - \beta^{-1}\Vert G_\beta(x)\Vert^2, 
            \end{align*}
            where at (*) we applied the substitution $G_\beta (x) - \nabla f(x)\in \partial h(x^+)$. 
            Comtinued from ($\nabla$) we obtain 
            \begin{align*}
                \underbrace{g(x^+) + h(x^+)}_{f(x^+)}
                & \le 
                \underbrace{g(z) + h(z)}_{f(x)} - \frac{1}{2\beta}\Vert G_\beta(x)\Vert^2 + \langle G_\beta, x - z\rangle
                \\
                f(x^+) - f(z) 
                &\le 
                \langle G_\beta(x), x - z\rangle - \frac{1}{2\beta}\Vert G_\beta(x)\Vert^2. \tag{$\star$}
            \end{align*}
            Next, we make the simplifications using algebra and get: 
            \begin{align*}
                f(x^+) - f(\bar x) 
                &\le 
                \frac{-1}{2\beta}\Vert G_\beta(x)\Vert^2
                + 
                \langle G_\beta, x - \bar x\rangle
                \\
                &= 
                -\frac{\beta}{2}(
                    \Vert x - x^+\Vert^2 - 2\langle x - x^+, x - \bar x\rangle
                )
                \\
                [5]
                \implies &= 
                \frac{-\beta}{2}(
                    \Vert x^+ - \bar x\Vert^2
                    - 
                    \Vert x - \bar x\Vert^2
                )
                \\
                &= 
                \frac{\beta}{2}(\Vert x - \bar x\Vert^2 - \Vert x^+ - \bar x\Vert^2), 
            \end{align*}
            and since the step-size assert an non-decreasing sequence of number, we perform the telescoping sum by considering the substitution $x^+ = x^{(k + 1)}, x = x^{(k)}$ we get: 
            \begin{align*}
                f(x^{(k + 1)}) - \bar f 
                &\le
                \frac{\beta}{2}(\Vert x^{(k)} - \bar x\Vert^2 - \Vert x^{(k + 1)} - \bar x\Vert^2)
                \\
                \implies
                \left(
                    \sum_{i = 0}^{N} f(x^{(i + 1)})
                    - \bar f
                \right)
                &\le
                \frac{\beta}{2}
                (\Vert x^{(0)} - \bar x\Vert^2 - \Vert x^{(N + 1)} - \bar x\Vert^2)
                \\
                f(x^{(N + 1)}) - \bar f & = 
                \min_{i = 0, \cdots, N}\left\lbrace
                    f(x^{(i + 1)}) - \bar f
                \right\rbrace \le 
                \left(
                    \frac{1}{N + 1}\sum_{i = 0}^{N}f(x^{(i + 1)})
                \right) - \bar f
                \\
                \implies
                f(x^{(N + 1)}) - \bar f
                &\le  
                \frac{\beta(\Vert x^{(0)} - \bar x\Vert^2 - \Vert x^{(N + 1)} - \bar x\Vert^2)}{2(N + 1)}
                \\
                &\le 
                \frac{\beta \Vert x^{(0)} - \bar x\Vert^2 }{2(N + 1)}. 
            \end{align*}
        \end{proof}
        \begin{remark}
            One important lemma that we can extract from this proof which will later be important for the proof for the accelerated case is the tagged expression ($\star$) in the above derivation. We will refers this as the ``Prox Step 2 Points" lemma. Expression $(\star)$ is equivalent to the lemma 2.3 in the FISTA paper\cite{paper:FISTA}. 
        \end{remark}
        \begin{lemma}[Prox Step 2 Points]\label{lemma:prox_two_p}
            With \hyperref[assumption:1]{assumption \ref*{assumption:1}}, and $\beta^{-1} > L_g$ still being our stepsize for \hyperref[alg:1]{algorithm \ref*{alg:1}}, let $y\in \mathbb E$ and define $y^+ = \mathcal P_{\beta^{-1}}^{g, h}(y)$ we have for any $x\in \mathbb E$: 
            \begin{align*}
                f(x) - f(y^+) \ge \frac{\beta}{2}\Vert y^+ - y\Vert^2 + 
                \beta \langle y - x, y^+ - y\rangle. 
            \end{align*}
        \end{lemma}
        \begin{proof}
            The proof is continuted from expression $(\star)$: 
            \begin{align*}
                f(x^+) - f(z) 
                &\le 
                \langle G_\beta(x), x - z\rangle - \frac{1}{2\beta}\Vert G_\beta(x)\Vert^2. 
                \\
                f(x^+) - f(z) & \le 
                \beta\langle x - x^+, x - z\rangle - \frac{1}{2\beta}\Vert \beta (x - x^+)\Vert^2
                \\
                f(z) - f(x^+) & \ge
                \frac{\beta}{2}\Vert x - x^+\Vert^2
                 + 
                \beta\langle x^+ - x, x - z\rangle, 
            \end{align*}
            and by substituting $x :=y$ and $z := x$ in the last line, we completed the proof of the lemma. 
        \end{proof}

\section{Accelerated Proximal Gradient}\label{sec:apg_intro}
    Here we state the Accelerated Proximal algorithm in Beck's Paper paper\cite{paper:FISTA}. The convergence rate will be stated. The convergence proof follows what is in the paper but with more details is in the appendix. The FISTA algorithm stands for Fast Iterative Shrinkage-Thresholding Algorithm, which is the specific case of the Proximal Gradient with Nesterive momentum applied to the LASSO problem. FISTA is an accelerated case of the ISTA algorithm and it is basically the same as FISTA but without the Nesterov momentum. 
    
    \subsection{Accelerated Proximal Gradient Algorithm} 
        \begin{algorithm}[H]\label{alg:fista_1} 
        \begin{algorithmic}[1]
            \STATE{\textbf{Input: the step size $\beta^{-1}$, and $x^{(0)}$ the initial guess. } }
            \STATE{$y^{(1)} = x^{(0)}$}
            \FOR{$k=1, \cdots, N$}
                \STATE{$x^{(k)}:= \mathcal Py^{(k)}$}
                \IF{$y^{(k)} - x^{(k)}$ small enough}
                    \STATE{Break}
                \ENDIF
                \STATE{$t_{k + 1} := \frac{1 + \sqrt{1 + 4t_k^2}}{2}$}
                \STATE{$y^{(k + 1)}:= x^{(k)} + \frac{t_k -1}{t_{k + 1}}(x^{(k)} - x^{(k - 1)})$}
            \ENDFOR
        \end{algorithmic}\caption{FISTA With Constant Step Size}
        \end{algorithm}

    \subsection{Convergence Under the Convex Case}
        \begin{theorem}[FISTA Convergence under Convexity]\label{thm:fista_convergence1}
            If \hyperref[assumption:1]{assumption \ref*{assumption:1}} is satisfied, then the FISTA algorithm has convergence result of: 
            \begin{align*}
                f(x^{(k)}) - f(\bar x) \le 
                \frac{2\beta^{-1}\Vert x^{(0)} - \bar x\Vert^2}
            {(k + 1)^2},
            \end{align*}
            where $\bar x$ is one of the optimizers and hence the rate of convergence is $\mathcal O(1/k^2)$. 
        \end{theorem}
        \begin{proof}
            For a proof see \hyperref[sec:fista1_proof]{appendix \ref*{sec:fista1_proof}}
        \end{proof}

\section{Numerical Experiments}\label{sec:numerical_experiments}
    In this section we consider a simple LASSO algorithm to demonstrate the convergence and then we demonstrate a way more complicated application of image deblurring with noises using the FISTA algorithm. 
    \subsection*{Simple LASSO}
        As the name suggested, we consider the overuse example problem of: 
        \begin{align*}
            \min_{x}\left\lbrace
                \frac{1}{2}\Vert Ax - b\Vert^2_2 + \lambda\Vert x\Vert_1    
            \right\rbrace
        \end{align*}
        For a brief background, This optimization problem commonly appears in the context of regression for generalized linear model where selection for sparse cofficients on the regression parameters is desired. Theoretically it corresponds to having a prior Laplace distribution for the regression parameters (See 11.4.1 in Murphy's\cite{book:ml_prob_murphy} book for more details.). The implementation is simple and the proximal gradient oracle for $\Vert \cdot \Vert_1$ is given as: 
        \begin{align*}
           (\text{prox}_{\lambda\Vert \cdot \Vert, t}(x))_i
           = 
           \text{sign}(x_i)\max(|x_i| - t\lambda, 0), 
        \end{align*}
        which can be interpreted the $\text{sign}$ function as the projection onto the interval $[-1, 1]$, and the $\max(|x| - t\lambda, 0)$ as the distance of $x$ to the set $[-t\lambda, t\lambda]$. The quantity $t$ here is the stepsize, and in our case the less than the reciprical of the maximum absolute eigenvalue of $A^TA$. 
        \par
        For this simple lasso problem, we make $A$ to be a diagonal 128 by 128 matrix, whose diagnals are points equally spaed in the interval $[0, 2]$. Observe that this is quadratic but not strongly convex. The right hand side vector $b$ is the same as the diagonal of matrix $A$, but with every odd index replaced with a guassian random noise on the level of $1^{-3}$. The experiment is performed using both ISTA and FISTA with $\lambda = 10^{-2}$, and both uses a step size of $0.2$(This is used to prevent triggering the line search routine in the implementation). The initial guess vector $x^{(0)}$ is a vector of all three, and it's the same for both FISTA, ISTA. 
        \par
        For the experiment we record and present the objective values $f$ for each of the iterations and the norm of the proximal mapping $\Vert x^{(k + 1)} - x^{(k)}\Vert_\infty$ in the none accelerated case and $\Vert y^{(k)} - x^{(k + 1)}\Vert_\infty$ in the accelerated case for each iteration. See \hyperref[fig:lasso_1]{figure \ref*{fig:lasso_1}} for an illustration. Both algorithm terminates whenever the norm of the proximal gradient mapping is less than $10^{-10}$ during the iteration. The norm is plotted on a log scale. Observe that the type of convergence for FISTA very different compare to the ISTA case. In the case of ISTA, the norm of the proximal mapping on the log plot resemble a curve at the start and quicktly changes its behaviors in the later iterations. The convergence of iteration after 2000 is a straight line. This is indicating a first order convergence of this quantity in the case of ISTA. In the case of FISTA, the overall rate of convergence is slower than ISTA for 2000 iterations and then it started to slow down; it converges faster regardless. The objective value is plotted on the left of \hyperref[fig:lasso_1]{figure \ref*{fig:lasso_1}}, and it's plotted on a log scale. The optimal value $f(\bar x)$ is assumed to be whenever the gradient mapping has a norm within $10^{-10}$. Observe that FISTA already reaches the optimal around 476 iterations disregarding the fact that the norm of the gradient mapping is not within the tolerance. 
        \begin{figure}[h]
            \centering
            \includegraphics*[width=8cm]{simple_lass_obj.png}
                \includegraphics*[width=8cm]{simple_lass_pgrad.png}
            \caption{The left is the objective value of the function during all iterations and the right side is the norm of the gradient mapping for all the iteraitons. }
            \label{fig:lasso_1}
        \end{figure}
        \begin{remark}
            In fact the convergence rate of the optimalith gap in general is linear when the smooth function $g$ is strongly convex, see theorem 10.29 of Beck's book\cite{book:first_order_opt} for the linear convergence of proximal gradient when acceleration is not used. There are other variants of FISTA such as the Restarted FISTA, their convergence bahviors is discussed in Beck book, Theorem 10.41 \cite{book:first_order_opt}.     
        \end{remark}
        
    \subsection*{Image Deblurring}
        We reproduced some of the experiments conducted in Beck's FISTA paper \cite{paper:FISTA} but using larger images with colors. We consider an cartoon image of a pink unicorn (I own the image) of 500 by 500 pixels, 3 color channels and it is blurred. The matrix $A$ that does the blurring, it is applying a discretized $15\times 15$ pixels guassian kernel with a variance of $4$ on all pixels with a periodic boundary condition across all color channel. The implementation for $A$ is a for loop that constructs sparse matrix $A$. The 750000 by 750000 sparse matrix $A$ acts on the vectorized image across all 3 channels independently. More efficient ways exist; such as using the kronecker product but for the sake of demonstration the alternatives are unexplored because with the explicit $A$ matrix I can reuse the code that made the previuos demonstration. 
        \par
        The vector $b = Ax^+ + \epsilon$ where $x^+$ is the flattend array of the original image of all tree color channel normalized to $[0, 1]$ using float64. The quantity $\epsilon$ is a zero mean guassian noise vector with zero mean and a variance of 2e-2. Here we define $\lambda = \alpha\times (3\times500^2)^{-1}$, and we make 3 experiments with $\alpha = 0, 0.01, 0.1$. The initial guess vector $x^{(0)}$ is a random zero mean guassian vector of unit variance. The blurred image is showed in \hyperref[fig:blurred_alto]{figure \ref*{fig:blurred_alto}}. And the results of the deblurring algorithm for different value of $\alpha$ is showed in \hyperref[fig:alto_deblurred]{figure \ref*{fig:alto_deblurred}}, observe that with $\lambda = 0$, the solution contains a lot of noise but with just a tiny abount of $\lambda$, the noise on the black blackground is prevented. 
        \begin{figure}[H]
            \centering
            \includegraphics*[width=5cm]{blurred_img.jpg}
            \caption{The image blurred by the Guassian Blurred matrix $A$ and with tiny amount of noise on the level of 2e-2. Zoom in to observe the tiny amount of Gaussian noise ontop of the blur.}
            \label{fig:blurred_alto}
        \end{figure}
        \begin{figure}[H]
            \centering
            \begin{subfigure}{0.31\textwidth}
                \includegraphics[width=5cm]{inverse_linear_experiment1-soln_img.jpg}
                \caption{} \label{fig:1a}
            \end{subfigure}     %
            \hspace*{\fill}     % maximize separation between the subfigures
            \begin{subfigure}{0.31\textwidth}
                \includegraphics[width=5cm]{inverse_linear_experiment2-soln_img.jpg}
                \caption{} \label{fig:1b}
            \end{subfigure}     %
            \hspace*{\fill}     % maximizeseparation between the subfigures
            \begin{subfigure}{0.31\textwidth}
                \includegraphics[width=5cm]{inverse_linear_experiment3-soln_img.jpg}
                \caption{} \label{fig:1c}
            \end{subfigure}
            \caption{(a) $\alpha = 0$, without any one norm penalty is not robust to the additional noise. (b) $\alpha = 0.01$, there is a tiny amount of $\lambda$. (c) $\alpha = 0.1$, a bit more pental compare to (a).}
            \label{fig:alto_deblurred}
        \end{figure}


\appendix
% \begin{section}{Proof for Convergence of FISTA}\label{sec:fista1_proof}
%     Here we prove \hyperref[thm:fista_convergence1]{theorem \ref*{thm:fista_convergence1}}. The proof closely follows Beck and Teboulle's work \cite{paper:FISTA}, and here we prove everything with extra details. 
%     \begin{subsection}{The First Lemma}
%         Recall from \hyperref[lemma:prox_two_p]{lemma \ref*{lemma:prox_two_p}}
%         and \hyperref[assumption:1]{assumption \ref*{assumption:1}}, instead of using $\beta^{-1}$ as our step size we use $L$. Here we introduce the notation $\delta_k = f(x^{(k)}) - f(\bar x)$ to denote the optimality gap at the $k$ iteration of the algorithm where $\bar x$ denotes one of the minimizer of the function $f$. 
%         \begin{lemma}[FISTA First Lemma]\label{lemma:fista_first_lemma}
%             The optimality gap generated via FISTA statisfies: 
%             \begin{align*}
%                 & 
%                 \frac{2}{L}t^2_k \Delta_k - \frac{2}{L}t^2_{k + 1} \Delta_{k + 1} 
%                 \ge 
%                 \Vert u^{(k + 1)}\Vert^2 - \Vert u^{(k)}\Vert^2
%                 \\
%                 & \Delta_k := f(x^{(k)}) - f(\bar x)
%                 \\
%                 & u^{(k)} := t_k x^{(k)} - (t_k - 1)x^{(k - 1)} - \bar x.
%             \end{align*}
%         \end{lemma}
%         \begin{proof}
%             We invoke the \hyperref[lemma:prox_two_p]{lemma \ref*{lemma:prox_two_p}} with $x = x^{(k)}, y = y^{(k +1)}$ to give: 
%             \begin{align*}\label{lemma:fista_first_lemma_1}
%                 f(x^{(k)}) - f\circ \mathcal P y^{(k + 1)}
%                 & \ge 
%                 \frac{L}{2}\Vert \mathcal Py^{(k + 1)} - y^{(k + 1)}\Vert^2 + 
%                 L \langle y^{(k + 1)} - x^{(k)}, 
%                     \mathcal Py^{(k + 1)} - y^{(k + 1)}
%                 \rangle
%                 \\
%                 f(x^{(k)}) - f(x^{(k + 1)}) 
%                 & \ge 
%                 \frac{L}{2}\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2 + 
%                 L 
%                 \langle 
%                     y^{(k + 1)} - x^{(k)}, 
%                     x^{(k + 1)} - y^{(k + 1)}
%                 \rangle, 
%                 \\
%                 \implies
%                 2L^{-1} (\Delta_k - \Delta_{k + 1}) 
%                 & \ge 
%                 \Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2 + 
%                 2\langle x^{(k + 1)} - y^{(k + 1)}, y^{(k + 1)} - x^{(k)}\rangle. 
%                 \tag{$*$}
%             \end{align*}
%             Observe that from the first line to the second line we invoke the definition for the updates for $x^{(k)}$ in the \hyperref[alg:fista_1]{FISTA Algorithm}. We then invoke the lemma again with $x:= \bar x, y = y^{(k + 1)}$, and it gives us: 
%             \begin{align*}
%                 f(\bar x) - f\circ \mathcal P y^{(k + 1)}
%                 & \ge 
%                 \frac{L}{2}\Vert \mathcal P y^{(k + 1)} - y^{(k + 1)}\Vert^2 
%                 + L 
%                 \langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle
%                 \\
%                 f(\bar x) - f(x^{(k + 1)}) 
%                 &\ge 
%                 \frac{L}{2}\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
%                 + 
%                 L \langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle
%                 \\
%                 -2L^{-1}\Delta_{k + 1}
%                 & \ge
%                 \Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
%                 + 
%                 2\langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle. 
%                 \tag{$\star$}
%             \end{align*}
%             Consider the expression $(t_k - 1)(*) + (\star)$, we obtain the LHS of that expression: 
%             \begin{align*}
%                 &(t_{k + 1} - 1)L^{-1} (\Delta_k - \Delta_{k + 1}) 
%                 -
%                 2L^{-1}\Delta_{k + 1}
%                 \\
%                 = \; &
%                 2L^{-1}
%                 ((t_{k + 1} + 1)\Delta_k - (t_{k + 1} - 1)\Delta_{k + 1} - \Delta_{k + 1})
%                 \\
%                 = \; &
%                 2L^{-1}((t_{k + 1} - 1)\Delta_k - t_{k + 1}\Delta_{k + 1}),
%                 \tag{$\star *$LHS}
%             \end{align*}
%             and then the RHS is: 
%             \begin{align*}
%                 & (t_{k + 1} - 1)\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
%                 + 
%                 2(t_{k + 1} - 1)\langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle 
%                 \\
%                 & \quad 
%                 + \Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
%                 + 
%                 2\langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle
%                 \\
%                 = \; &
%                 t_{k + 1}\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
%                 + 
%                 \langle 
%                     x^{(k + 1)} - y^{(k + 1)}, 
%                     \underbrace{2(t_{k + 1} - 1)(y^{(k + 1)} - x^{(k)}) + 2(y^{(k + 1)} - \bar x) }_
%                     {
%                         = 2(t_{k + 1}y^{(k + 1)} + (1 - t_{k + 1})x^{(k)} - \bar x)
%                     }
%                 \rangle
%                 \\
%                 = \; & 
%                 t_{k + 1}\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
%                 + 
%                 2\langle 
%                     x^{(k + 1)} - y^{(k + 1)}, 
%                     t_{k + 1}y^{(k + 1)} + (1 - t_{k + 1})x^{(k)} - \bar x
%                 \rangle. 
%                 \tag{$\star *$RHS}
%             \end{align*}
%             The entirety of expression (3) is given by: 
%             \begin{align*}
%                 & 2L^{-1}((t_{k + 1} - 1)\Delta_k - t_{k + 1}\Delta_{k + 1})
%                 \ge 
%                 t_{k + 1}\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
%                 \\
%                 & \quad 
%                 + 
%                 2\langle 
%                     x^{(k + 1)} - y^{(k + 1)}, 
%                     t_{k + 1}y^{(k + 1)} + (1 - t_{k + 1})x^{(k)} - \bar x
%                 \rangle. 
%                 \tag{$\star *$}
%             \end{align*}
%             The next part of the proof shows some of the magics involves in changing the LHS,RHS of $(\star *)$ to be the similar to what is in the theorem statement. It's accomplished by the relations for the sequence $t_k$, more specifically it's hinged on the relations $t_k^2 = t^2_{k + 1} - t_{k + 1}$ which is asserted by the FISTA algorithm. Using this fact we proceed by multiplying $t_{k + 1}$ on both sides of $(\star *)$ and obtain: 
%             \begin{align*}
%                 & 2L^{-1}(\Delta_k t_k^2 - \Delta_{k + 1}t_{k + 1}^2)
%                 \\
%                 & \hspace{2em}
%                 \begin{aligned}
%                     & \ge 
%                     \Vert t_{k + 1}(x^{(k + 1)} - y^{(k + 1)})\Vert^2 - 
%                     2\langle 
%                         t_{k + 1}(x^{(k + 1)} - y^{(k + 1)}), 
%                         t_{k + 1}y^{(k + 1)} - 
%                         (t_{k + 1} - 1)x^{(k)} - \bar x
%                     \rangle
%                 \end{aligned}
%                 \\
%                 & 2L^{-1}(\Delta_k t_k^2 - \Delta_{k + 1}t_{k + 1}^2)
%                 \\ 
%                 &\hspace{2em}
%                 \begin{aligned}
%                     & \ge 
%                     \Vert 
%                         \underbrace{t_{k + 1}x^{(k + 1)}}_{
%                             =:a
%                         } - \underbrace{t_{k + 1}y^{(k + 1)}}_{
%                             =:b
%                         }
%                     \Vert^2 
%                     - 
%                     2\langle 
%                     \underbrace{ t_{k + 1}x^{(k + 1)}}_{=:a} - t_{k + 1}y^{(k + 1)}, 
%                         \underbrace{t_{k + 1}y^{(k + 1)}}_{=:b} - 
%                         \underbrace{((t_{k + 1} - 1)x^{(k)} + \bar x)}_{=:c}
%                     \rangle
%                     \\
%                     & \ge 
%                     \Vert a - b\Vert^2 + 2\langle a - b, b -c\rangle
%                     \\
%                     & = 
%                     \Vert a - b\Vert^2 + \Vert b - c\Vert^2 + 
%                     2\langle a-b, b -c\rangle - \Vert b - c\Vert^2
%                     \\
%                     &= 
%                     \Vert a - c\Vert^2 - \Vert b - c\Vert^2
%                     \\
%                     &\ge 
%                     \Vert 
%                         t_{k+ 1}x^{(k + 1)} - 
%                         (t_{k + 1} - 1)x_k - \bar x 
%                     \Vert^2 - 
%                     \Vert 
%                         (t_{k + 1} - 1)x^{(k)} - t_{k + 1}y^{(k + 1)}
%                         - \bar x
%                     \Vert^2, 
%                 \end{aligned}
%             \end{align*}
%             to prove the lemma, we need to match the form in the above 2 norm of the vector, we accomplish this by considering FISTA algorithm: 
%             \begin{align*}
%                 t_{k + 1}y^{(k + 1)} &= t_{k + 1}x^{(k)} + (t_k - 1)(x^{(k)} - x^{(k - 1)})
%                 \\
%                 t_{k + 1}y^{(k + 1)} - (t_{k + 1}- 1)x^{(k)}
%                 &= t_{k + 1}x^{(k)} - (t_{k + 1}- 1)x^{(k)} + (t_k - 1)(x^{(k)} - x^{(k - 1)})
%                 \\
%                 &= 
%                 x^{(k)} + (t_k - 1)x^{(k)} - (t_k - 1)x^{(k - 1)}
%                 \\
%                 &= t_kx^{(k)} - (t_k - 1)x^{(k - 1)}, 
%             \end{align*}
%             cf from previously we have: 
%             \begin{align*}
%                 & 2L^{-1}(\Delta_k t_k^2 - \Delta_{k + 1}t_{k + 1}^2)
%                 \\
%                 &\ge 
%                 \Vert 
%                     t_{k + 1}x^{(k + 1)}
%                     + 
%                     (1 - t_{k + 1}) x^{(k)} - \bar x
%                 \Vert^2
%                 - 
%                 \Vert t_kx^{(k)} + (1 - t_k)x^{(k -1)} - \bar x\Vert^2
%                 \\
%                 & \ge \Vert u^{(k + 1)}\Vert^2 - \Vert u^{(k)}\Vert^2.
%             \end{align*}
%             And that completes the proof of the Second Lemma. 
%         \end{proof}
%         \begin{remark}
%             There should be some point, where we can infer the properties of the sequence $t_k$ instead of taking the sequence from FISTA algorithm for granted, there should also be a way to make a different decision during the proof so that this becomes the proof for the algorithm without the accelerations technique. 
%         \end{remark}
%     \end{subsection}

%     \begin{subsection}{The Second Lemma}
%         \begin{lemma}[FISTA Second Lemma]
%             Let $\{a, b\}$ be positive real numbers sequence satisfying: $a_k - a_{k - 1}\ge b_{k + 1} - b_k, \forall k \ge 1$, with $a_1 + b_1 \le c, c > 0$, and then it would mean that $a_{k + 1}\le c$. 
%         \end{lemma}
%         \begin{proof}
%             The base case of the proof is obvious by the fact that $b_1$ is positive, hence $a_1 \le c$ is true. the relation automatically holds true for all $k\ge 1$ because $a_k - a_{k + 1}\ge b_{k + 1} - b_k \implies a_k + b_k \le c$, then $a_k - a_{k + 1}\ge b_{k + 1} - b_k \implies a_k + b_k \le a_{k + 1} + b_{k + 1} \implies a_{k + 1} + b_{k + 1} \le c\implies a_{k + 1}\le c$. 
%         \end{proof}
%     \end{subsection}

%     \begin{subsection}{The Third Lemma}
%         \begin{lemma}[FISTA Third Lemma]
%             The FISTA asserts $t_k \ge (k + 1)/2, \forall k \ge 1$. 
%         \end{lemma}
%         \begin{align*}
%             t_k 
%             &\ge \frac{k + 1}{2}
%             \\
%             4t_k^2 
%             &\ge 4\left(
%                 \frac{k + 1}{2}
%             \right)^2
%             \\
%             \implies 
%             t_k &= \frac{1}{2}\left(
%                 1 + \sqrt{1 + 4t_k^2}
%             \right)
%             \\
%             &= 
%             \frac{1}{2} + \frac{\sqrt{1 + (k + 1)^2}}{2}
%             \\
%             & \ge \frac{1 + k}{2}, 
%         \end{align*}
%     \end{subsection}
%     \subsection{Convergence Proof}
%         Firstly we define the quantities: 
%         \begin{itemize}
%             \item [1.] $a_k := (2/L)t_k^2 \Delta_k$.
%             \item [2.] $b_k := \Vert u^{(k)}\Vert^2$.
%             \item [3.] $c:= \Vert x^{(0)} - \bar x\Vert^2 = \Vert y^{(1)} - \bar x\Vert^2$. 
%         \end{itemize}
%         Recall from the first lemma, and we can represents it using the quantities listed above: 
%         \begin{align*}
%             2L^{-1}(\Delta_kt_k^2 - \Delta_{t + 1}t_{k + 1}^2) 
%             &\ge 
%             \Vert u^{(k + 1)}\Vert^2 - \Vert u^{(k)}\Vert^2
%             \\
%             a_k - a_{k + 1} &\ge 
%             b_{k + 1} - b_k, 
%         \end{align*}
%         To demonstrate how the base case hold up for the second lamma, we consider \hyperref[lemma:prox_two_p]{lemma \ref*{lemma:prox_two_p}}, substituting $x^{(1)}$ for $x$ and $\bar x$ for $y$, implicitly using the fact that $\bar x$ is a fixed point of $\mathcal P$: 
%         \begin{align*}
%             \Delta_1& \ge 
%             \frac{L}{2}\Vert \mathcal Py^{(1)} - y^{(1)}\Vert^2 + L 
%             \langle y^{(1)} - \bar x, \mathcal P y^{(1)} - y^{(1)}\rangle
%             \\
%             & =
%             \frac{L}{2}\Vert \mathcal P x^{(1)} - y^{(1)}\Vert^2 + L 
%             \langle x^{(1)} - \bar x, x^{(1)} - y^{(1)}\rangle
%             \\
%             &= 
%             \frac{L}{2}
%             (\Vert x^{(1)} - \bar x\Vert^2 - \Vert y^{(1)} - \bar x\Vert^2)
%             \\
%             \implies
%             2L^{-1}\Delta_1 
%             &\le
%             \underbrace{\Vert y^{(1)} - \bar x\Vert^2}_{=c} - \Vert x^{(1)} - \bar x\Vert^2
%             \\
%             \implies
%             a_1 + b_1
%             & \le c, 
%         \end{align*}
%         using the fact that $t_1 = 1$ we have $u^{(1)} = x^{(1)} - \bar x \implies b_1 = \Vert x^{(1)} - \bar x\Vert^2$, please observe that the above expression simplifies to $a_1 + b_1 \le c$. Invoking the second lemma, we have the claim that $a_{k + 1}\le c$, which is stated as: 
%         \begin{align*}
%             2L^{-1}t_{k + 1}^2\Delta_{k + 1} 
%             &\le \Vert x^{(0)} - \bar x\Vert^2
%             \\
%             \implies
%             \Delta_{k + 1}
%             &\le 
%             \frac{L\Vert x^{(0)} - \bar x\Vert^2}{2t_k^2}
%             \\
%             & \le 
%             \frac{L\Vert x^{(0)} - \bar x\Vert^2}{2 \times 2^{-2}(k + 1)^2}
%             = 
%             \frac{2L\Vert x^{(0)} - \bar x\Vert^2}{(k + 1)^2}, 
%         \end{align*}
%         and the proof is now complete.         
% \end{section}

\section{A Slightly Better Proof For Convergence For FISTA}
    In this section we go through a proof that I made personally that doesn't require the momentum sequence $t_k$ for the FISTA algorith under \hyperref[assumption:1]{assumption \ref*{assumption:1}}. We prepare the following template algorithm: 
    \begin{algorithm}
        \begin{algorithmic}[1]
            \STATE{\textbf{Input:} $x^{(0)}, x^{(-1)}, L, h, g$; 2 initial guesses and stepsize L}
            \STATE{$y^{(0)} = x^{(0)} + \theta_k (x^{(0)} - x^{(-1)})$}
            \FOR{$k = 1, \cdots, N$}
                \STATE{$x^{(k)} = \text{prox}_{h, l^{-1}}(y^{(k)} + l^{-1}\nabla g(y^{(k)})) =: \mathcal Py^{(k)}$}
                \STATE{$y^{(k + 1)} = x^{(k)} + \theta_k(x^{(k)} - x^{(k - 1)})$}
            \ENDFOR
        \end{algorithmic}
        \caption{Template Proximal Gradient Method With Momentum}\label{alg:fista_template}
    \end{algorithm}
    \subsection{Preparations}
        \hyperref[alg:fista_template]{Algorithm \ref*{alg:fista_template}} is a template algorithm without any spceific assumptions about $\theta_k$ and it's up to ourselves to find out the best update sequences for the momentum parameters $\theta_k$. To make the proof more intuitive than Beck's proof \cite{paper:FISTA}, we consider the following list of quantities that is more informative: 
        \begin{itemize}
            \item [1.] $v^{(k)} = x^{(k)} - x^{(k -1)}$ is the velocity term. 
            \item [2.] $\bar v^{(k)}= \theta_k v^{(k)}$ is the weighed velocity term. 
            \item [3.] $e^{(k)} := x^{(k)} - \bar x$, where $\bar x \in \arg\min_{x}(f(x))$, where $\bar x$ might not be unique. 
            \item [4.] $\Delta_k := f(x^{(k)}) - f(\bar x)$ which represent the optimality gap at step $k$. 
        \end{itemize}
    \subsection{The Momentum Magic}
        We now begins the next part where we look for the right place to insert momentum. We start by considering the prox 2 point lemma (\hyperref[lemma:prox_two_p]{lemma \ref*{lemma:prox_two_p}}) and substitute $x = x^{(k)}, y = y^{(k + 1)}$ gives: 
        \begin{align*}
            f(x^{(k)}) - f\circ \mathcal Py^{(k + 1)}
            &\ge 
            \frac{L}{2}\Vert \mathcal Py^{(k + 1)} - y^{(k + 1)}\Vert^2 + 
            L \langle y^{(k + 1)} - x^{(k)}, \mathcal P y^{(k + 1)} - y^{(k + 1)}\rangle 
            \\
            [*1]\implies
            2L^{-1} (\Delta_k - \Delta_{k + 1}) 
            &\ge 
            \Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2 + 
            2 \langle x^{(k + 1)} - y^{(k + 1)}, y^{(k + 1)} - x^{(k)}\rangle
            \\
            [*2]\implies
            2L^{-1} (\Delta_k - \Delta_{k + 1})  
            & \ge 
            \textcolor{red}
            {
                \Vert 
                    v^{(k + 1)} - \bar v^{(k)}
                \Vert^2
            }
             + 
            2\langle \textcolor{violet}{v^{(k + 1)} - \bar v^{(k)}}, \bar v^{(k)}\rangle
            \tag{*}
        \end{align*}
        where we make use of the fact that $x^{(k + 1)} = \mathcal P y^{(k + 1)}$ at [$*1$], and using $x^{(k + 1)} - y^{(k + 1)} = x^{(k + 1)} - x^{(k)} - \bar v^{(k)} = v^{(k + 1)} - \bar v^{(k)}$ at [$*2$]. Similarly we can use the prox 2 points lemma (\hyperref[lemma:prox_two_p]{lemma \ref*{lemma:prox_two_p}}) and substitute $x = \bar x, y = y^{(k + 1)}$, giving us: 
        \begin{align*}
            -2L^{-1}\Delta_{k + 1} 
            &\ge 
            \Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2 + 2
            \langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle
            \\
            -2L^{-1}\Delta_{k + 1} 
            & \ge 
            \textcolor{red}
            {
                \Vert 
                    v^{(k + 1)} - \bar v^{(k)}
                \Vert^2
            } + 
            2\langle  
                \textcolor{violet}{v^{(k + 1)} - \bar v^{(k)}},
                e^{(k)} + \bar v^{(k)}
            \rangle.
            \tag{$\star$}
        \end{align*}
        we make use of the fact that $y^{(k + 1)} = x^{(k)} - \bar v^{(k)}$, then $y^{(k + 1)} - \bar x = x^{(k)} - \bar v^{(k)} - \bar x = e^{(k)} - \bar v^{(k)}$. In the case without acceleration, we essentially considered expression $(\star)$ and did some algebra so that it can be summed up like a telescoping series, similar to the proof we did in \hyperref[thm:convergence_non_accelerated]{theorem \ref*{thm:convergence_non_accelerated}} case, here we consider the following linear combinations of $(*), (\star)$ such that it leaves $v^{(k)} - \bar v^{(k)}$ inside of the cross term with a multiplier $t_{k + 1}$, let's call it $t_k$ (Just a generic sequence that will contributes to the engineering of the algorithm), to do that we consider $(t_{k + 1}- 1)(*) + (\star)$ with $(t_k - 1)\ge 0$ for all $k$ giving us: 
        \begin{align*}
            & 2L^{-1}((t_{k + 1} - 1)\Delta_k - t_{k + 1}\Delta_{k + 1})
            \\
            & \ge 
            t_{k + 1}
            \textcolor{red}{\Vert v^{(k + 1)} - \bar v^{(k)}\Vert^2} + 
            2\langle 
                \textcolor{violet}{t_{k + 1}(v^{(k + 1)} - \bar v^{(k)})}, e^{(k)} + t_{k + 1} \bar v^{(k)}
            \rangle, 
            \tag{$*\star$}
        \end{align*}
        unfortunately, at current step we won't be able to trigger the monotone property and sum it up like in the case without any momentum due to the term $t_{k + 1}$, instead, we need to consider new approach. In the next section, we point out a format for 2 bounded sequences where the above expression can be reduced to with some conditions on the sequence $t_k$. 
    \subsection{2 Bounded Sequences}
        For the sake of idealization, we may assumes that there might exists a way to write $(*\star)$ in the format of $a_k- a_{k + 1}\ge b_{N+ 1} - b_k$. Therefore we introduce the following lemma: 
        \begin{lemma}{2 Bounded Sequences}
            We consider sequence $a_k, b_k \ge 0$ for $k\in \mathbb N$ with $a_1 + b_1 \le c$, and inductively the 2 sequences satisfies: $a_{k} - a_{k + 1} \le b_{k + 1} - b_k$ , which describes a sequence whose oscillations is bounded by the difference of another sequence. Consider the telescoping sum: 
            \begin{align*}
                a_{k} - a_{k + 1} 
                &\ge b_{k + 1} - b_k \quad \forall k \in \mathbb N
                \\
                \implies
                -\sum_{k = 1}^{N}
                a_{k + 1} - a_k 
                &\ge 
                \sum_{k = 1}^{N} b_{k + 1} - b_k
                \\
                - (a_{N + 1} - a_1) 
                &\ge b_{N + 1} - b_1
                \\
                c\ge a_1 + b_1
                &\ge
                b_{N + 1} + a_{N +1}
                \\
                \implies c \ge a_{N+1}. 
            \end{align*}
        \end{lemma}
        \begin{remark}
            If we can match the form of the expression, then there is a way to restrain the value of $\Delta_k$, intuitive we are thinking of bounding the changes in the sequence. If the initial $a_1 + b_1$  is bounded by $c$, and the way $a_k$ changes is always bounded by the changes in $b_k$, given both $a_k, b_k$ are non-negative, the total amount of changes of $a_k$ will be bounded by the total amount of changes in the sequence $b_k$ as well. 
            \par
            Additionally, we may consider adding a residual term for the sequences $a_{k} - a_{k + 1} \ge b_{k + 1} - b_k + r_k$ with a residual term, then the results $a_{N + 1}$ would be bounded by a larger quantity.
        \end{remark}
    \subsection{Form Matching}
        We consider the expression $(*\star)$ from previously, and our goal is to match the coefficient of the term so that they can be matched with the form: $a_k - a_{k + 1}\le b_{k + 1} - b$, to accomplish, we further simplifies $(*\star)$ by multiplying both side by $t_{k + 1}$ (so that we can move the constant to the inside of the norm instead of letting it dangling outside) and we assume it to be a positive quantity larger than one: 
        \begin{align*}
            & \quad 2L^{-1}((t_{k + 1}^2 - t_{k + 1})\Delta_k - t_{k + 1}^2\Delta_{k + 1})
            \\
            & \ge  
            t_{k + 1}^2\Vert v^{(k + 1)} - \bar v^{(k)}\Vert^2 + 
            2\langle t_{k + 1}^2(v^{(k + 1)} - \bar v^{(k)}), e^{(k)} + t_{k + 1} \bar v^{(k)}\rangle
            \\
            &=
            \Vert t_{k + 1} (v^{(k + 1)} - \bar v^{(k)}) \Vert^2 + 
            2\langle t_{k + 1}^2(v^{(k + 1)} - \bar v^{(k)}), e^{(k)} + t_{k + 1}\bar v^{(k)}\rangle
            \\
            &=
            \Vert t_{k+1} v^{(k + 1)} - t_{k + 1}\bar v^{(k)} + e^{(k)} + t_{k + 1}\bar v^{(k)}\Vert^2
            - 
            \Vert e^{(k)} - t_{k + 1} \bar v^{(k)}\Vert^2
            \\
            &=
            \Vert 
                t_{k+1} v^{(k + 1)} + e^{(k)}
            \Vert^2
            - 
            \Vert e^{(k)} - t_{k + 1} \bar v^{(k)}\Vert^2
            \\
            [1]\implies
            & = 
            \Vert t_{k + 1}v^{(k + 1)} + e^{(k)}\Vert^2
            - 
            \Vert v^{(k)} + e^{(k - 1)} + t_{k + 1}\bar v^{(k)} \Vert^2
            \\
            & = 
            \Vert t_{k + 1}v^{(k + 1)} + e^{(k)}\Vert^2
            - 
            \Vert e^{(k - 1)} + (t_{k + 1}\theta_k + 1) v^{(k)} \Vert^2, 
            \tag{$\star \star$}
        \end{align*}
        where at [1] we use the fact that $e^{(k)}= x^{(k)} - \bar x = x^{(k)} - x^{(k - 1)}+ x^{(k - 1)} - \bar x = v^{(k)} - e^{(k)}$ and to match the form, we would need the sequence of $t_k, \theta_k$ to satisfies
        \begin{align*}
            \begin{cases}
                t^2_{k + 1} - t_{k + 1} = t_k^2,
                \\
                t_k = t_{k + 1}\theta_k + 1. 
            \end{cases}
            \tag{$\star **$}
        \end{align*}
        One of the options is the sequence suggested in the FISTA paper, stated as: 
        \begin{align*}
            t_k &= \frac{1 + \sqrt{1 + 4t_k^2}}{2}, 
            \\
            \theta_k &= \frac{t_k - 1}{t_{k + 1}}, 
            \tag{$\star \star *$}
        \end{align*}
        and with this sequences in mind, we can express $(\star\star)$ in the form of:
        \begin{align*}
            \underbrace{2L^{-1}t_k^2\Delta_k}_{a_k} - \underbrace{2L^{-1}t_{k + 1}^2\Delta_{k + 1}}_{a_{k + 1}}
            \ge 
            \underbrace{\Vert t_{k + 1}v^{(k + 1)} + e^{(k)}\Vert^2}_{b_{k + 1}}
            - 
            \underbrace{\Vert e^{(k - 1)} + t_k  v^{(k)} \Vert^2}_{b_{k}}, 
        \end{align*}
        which has $a_k = 2L^{-1}\Delta_{k + 1}$finally, we observe that setting $k = 1$ on $(\star)$ gives: 
        \begin{align*}
            -2L^{-1}  \Delta_1
            & \ge 
            \Vert v^{(1)} - \bar v^{(0)}\Vert^2 + 
            2\langle e^{(0)} - \bar v^{(0)}, v^{(1)} - \bar v^{(0)}\rangle
            \\
            &\ge
            \Vert 
                v^{(1)} - \bar v^{(0)}
                + 
                e^{(0)} - \bar v^{(0)}
            \Vert^2
            - 
            \Vert 
                e^{(0)} - \bar v^{(0)}
            \Vert^2
            \\
            \Vert e^{(0)} - v^{(0)}\Vert^2
            & \ge 
            \Vert v^{(1)} + e^{(0)}\Vert^2 + 2L^{-1}\Delta_1, 
        \end{align*}
        now we let $a_1 = 2L^{-1}\Delta_1$, which implies $t_1 = 1$, and hence we also have $b_1 = \Vert v^{(1)} + e^{(0)}\Vert^2$ with $c = \Vert e^{(0)} - v^{(0)}\Vert^2$, and this completes the base case for using the sequence lemma. Applying the lemma we obtain: 
        \begin{align*}
            a_{N + 1} &\le c
            \\
            2L^{-1}t_{N + 1}^2\Delta_{N + 1} &\le \Vert e^{(0)} - v^{(0)}\Vert^2.
        \end{align*}
        interestingly, the sequence defined in $t_k$ has a lower bound of $(k + 1)/2$, which will assert convergence for the above expression. 

\bibliographystyle{plain}
\bibliography{refs.bib}
\end{document}