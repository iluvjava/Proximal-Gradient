\documentclass[]{article}
\usepackage{amsmath}
\usepackage{amsfonts} 
\usepackage[english]{babel}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage{algorithmic}
\usepackage{algorithm}
% \usepackage{minted}
% Basic Type Settings ----------------------------------------------------------
\usepackage[margin=1in,footskip=0.25in]{geometry}
\linespread{1}  % double spaced or single spaced
\usepackage[fontsize=12pt]{fontsize}
\usepackage{authblk}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}       % Theorem counter global 
\newtheorem{prop}{Proposition}[section]  % proposition counter is section
\newtheorem{lemma}{Lemma}[subsection]  % lemma counter is subsection
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}[subsection]
{
    % \theoremstyle{plain}
    \newtheorem{assumption}{Assumption}
}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}
\usepackage[final]{graphicx}
\usepackage{listings}
\usepackage{courier}
\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}
\newcommand{\indep}{\perp \!\!\! \perp}
\usepackage{wrapfig}
\graphicspath{{.}}
\usepackage{fancyvrb}

%%
%% Julia definition (c) 2014 Jubobs
%%
\usepackage[T1]{fontenc}
\usepackage{beramono}
\usepackage[usenames,dvipsnames]{xcolor}
\lstdefinelanguage{Julia}%
  {morekeywords={abstract,break,case,catch,const,continue,do, else, elseif,%
      end, export, false, for, function, immutable, import, importall, if, in,%
      macro, module, otherwise, quote, return, switch, true, try, type, typealias,%
      using, while},%
   sensitive=true,%
   alsoother={$},%
   morecomment=[l]\#,%
   morecomment=[n]{\#=}{=\#},%
   morestring=[s]{"}{"},%
   morestring=[m]{'}{'},%
}[keywords,comments,strings]%
\lstset{%
    language         = Julia,
    basicstyle       = \ttfamily,
    keywordstyle     = \bfseries\color{blue},
    stringstyle      = \color{magenta},
    commentstyle     = \color{ForestGreen},
    showstringspaces = false,
}
\title{Proximal Gradient: Convergence, Implementations and Applications}
\author{Hongda Li}

\begin{document}
\maketitle
\begin{abstract}
    We prove the proximal gradient and accelerated proximal gradient algorithm convergence rate under convexity assumptions. We proved the convergence for the proximal gradient without the Nesterov Acceleration differently compared to the original work by Beck\cite{paper:FISTA}; we extract a lemma and then use it to prove the convergence rate under the accelerated case. Additionally, we provide thorough context for the proximal gradient method by incorporating the majorization via envelope idea. Finally, we did a numerical experiment different from Beck's original work by keeping track of the norm of the fixed point error on the proximal gradient step during our numerical experiment to expose a 2 phase descent property. 
\end{abstract}

\numberwithin{equation}{subsection}
\section{Introduction}
    We are concerned with the problem type
    \begin{align}
        \min_{x} g(x) + h(x),
    \end{align}
    where the objective is the sum of two functions. Algorithms developed for solving optimization problems of this format. We will list some algorithms with their convergence rate under different assumptions. 
    \begin{enumerate}
        \item [1.] The projected subgradient algorithm solves $h = \delta_Q$ where $Q$ is a closed convex set, and $g$ is closed and convex with $Q\subseteq\text{ri}\circ \text{dom}(g)$. The algorithm generates a sequence of $x^{(k)}$ where the weighted average of the sequence by step size has a convergence rate of $\mathcal O(1/\sqrt{k})$ in terms of the optimality; this result is from the convex analysis class I took before. For a more thorough exposition of the matter regarding the convergence of the optimality for the subgradient method under the choice of Polyak Step Size, refer to Theorem 8.13 of Beck's work\cite{book:first_order_opt}. 
        \item [2.] We use the proximal Gradient algorithm when $g$ is strongly smooth, convex, closed, and proper function and $h$ has an easy-to-compute proximal oracle. Assuming $h$ is closed convex, proper, and coersive, the optimal and the minimizer exists, and the convergence rate is $\mathcal O(1/k)$. We will prove this result in our report. 
        \item [3.] The Accelerated Proximal Algorithm is a modified version of the proximal gradient that uses Nesterov Momentum and converges with $\mathcal O(1/k^2)$ with an additional convexity assumption on $g$. The convergence can be even faster when more additional assumptions on $g$. We will prove the convergence results using the convexity assumption in this report.  
    \end{enumerate}
    In this report, we introduce the setup for the proximal gradient algorithms. We give proofs for the convergence results of the Proximal Gradient algorithms with fixed step sizes with and without the Nesterov Momentum. Finally, we also implemented some nontrivial examples of the algorithm in Julia. The code that produces the plots for the numerical experiments is on my GitHub \href{https://github.com/iluvjava/Proximal-Gradient}{here}. 
    \par
    For this report, some of the materials are in Amir Beck's textbook \cite{book:first_order_opt}, and the proof for the convergence of the Accelerated Proximal Gradient method closely follows the original paper for FISTA\cite{paper:FISTA} by Amir and Marc Teboulle. Other additional and specific materials might get used during the expression as well. 
    \par 
    In the \hyperref[sec:preliminaries]{section \ref*{sec:preliminaries}}, we introduce the minimum mathematical background needed to understand the proximal gradient method. In the second \hyperref[sec:pg_forward_backward_env]{section \ref*{sec:pg_forward_backward_env}}, we introduce the proximal gradient method using the forward-backward envelope and the idea of majorization minimization. In addition, we introduce several fundamental lemmas related to the monotone property of the Proximal Gradient method and the choice of step size and extract out the important \hyperref[lemma:prox_two_p]{lemma \ref*{lemma:prox_two_p}} for the proof of the accelerated case, which is in the appendix. In \hyperref[sec:pg_convergence]{section \ref*{sec:pg_convergence}}, we prove the convergence of the proximal gradient method under convexity and smoothness assumption with a fixed step size. Moreover, in \hyperref[sec:apg_intro]{section \ref*{sec:apg_intro}}, we state the proximal gradient algorithm with Nesterov acceleration (also referred to as FISTA). In the \hyperref[alg:fista_1]{appendix \ref*{sec:fista1_proof}}, we prove the better convergence of FISTA with meticulous detail without explicitly assuming that momentum term. Finally, for applications in \hyperref[sec:numerical_experiments]{section \ref*{sec:numerical_experiments}}, we consider the convergence of the optimality and the norm of the gradient mapping for the LASSO problem, and then we apply the LASSO algorithm for the task of deblurring images with high gaussian noise. In that section, we introduce other typical applications and extensions of the algorithm. 
    \subsection{Contributions}
        Nesterov first created gradient descent with momentum in 1983; Beck's contribution involves proving that the Nesterov accelerations work for the proximal gradient method. Beck popularized the use of momentum in the broader context to improve the convergence of algorithms such as the proximal gradient method. In our report, we made the following contributions: 
        \begin{itemize}
            \item [1.] We prepare the theoretical context and background for the proximal gradient algorithm. We use the majorizations and minimizations interpretations to derive the proximal gradient algorithm. 
            \item [2.] We organize the proof for the proximal gradient method without momentum and present it; we extract a lemma that is fundamental to the proof of the proximal gradient method with the Nesterov accelerations term. 
            \item [3.] We prove the accelerated proximal gradient algorithm without prior assumptions on the sequence which produces the momentum term. Instead, we assume a template algorithm with a momentum term and derive some desired properties for the sequence $t_k$ instead of assuming it in advance. 
            \item [4.] We implemented the proximal gradient algorithm in Julia and applied the algorithm to the LASSO problem for denoising images. We use the algorithm for a larger image and collect the norm of the fixed point error of the proximal gradient operator while tuning the algorithm. We present the results and show that the convergence of the fixed point error follows a 2 phase descend pattern.
        \end{itemize}

\section{Preliminaries}\label{sec:preliminaries}
    The proximal operator is a crucial component of the algorithm, and its non-expansive property is relevant to the convergence of the Proximal Gradient under the non-convex case. We will not go into detail about the non-convex case. Under the assumption of convexity for $f$, the property of the strongly smooth function is more relevant. 
    \subsection{The Proximal Operator}
        \begin{definition}[Proximal Operator and Moreau Envelope]
            A Moreau Envelope $\text{env}_{\alpha, f}(x)$, $\text{prox}_{\alpha, f}$ the proximal operator are defined for some function $f$: 
            $$
            \begin{aligned}
                & \text{env}_{f, \alpha}(x) := \min_{y}\left\lbrace
                    f(y) + \frac{1}{2 \alpha }\Vert y - x\Vert^2
                \right\rbrace, 
                \\
                & \text{prox}_{f, \alpha}(x) := 
                \arg\min_{y}\left\lbrace
                    f(y) + \frac{1}{2\alpha} \Vert y - x\Vert^2
                \right\rbrace. 
            \end{aligned}
            $$
        \end{definition}
        The proximal operator is a singleton when the function $f$ is convex, proper, and closed due to the strong convexity of $f(y) + 1/(2\alpha)\Vert y - x\Vert^2$. Observe that $\text{env}_{\alpha, f}(x) = (f\square \frac{1}{2\alpha}\Vert \cdot \Vert^2)(x)$, hence the infimal convolution gives us the interpretation that the epigraphs of the envelope are adding between the epigraph of these two functions. This conceptualization will help with the intuitive understanding of many proximal algorithms. 
        In addition, please observe the following identities: 
        $$
        \begin{aligned}
            & \text{prox}_{f/\alpha, 1} =  \text{prox}_{f, \alpha}
            \\
            & \alpha^{-1}\text{env}_{\alpha f, 1}(x) = \text{env}_{f, \alpha}(x). 
        \end{aligned}
        $$
        % \begin{prop}[Proximal Operator is a Nonexpansive Mapping]
        %     Let $f:\mathbb E \mapsto \mathbb{\bar R}$ be a closed, convex proper function. then $\text{prox}_f(x)$, with $\alpha= 1$ is a singleton for every point $x\in \mathbb E$. Moreoever, for any points $x, y\in \mathbb E$ the estimate holds: 
        %     $$
        %         \begin{aligned}
        %             \Vert \text{prox}_f(x) - \text{prox}_f(y)\Vert^2_\star \le 
        %             \langle \text{prox}_f(x) - \text{prox}_f(y), x - y\rangle. 
        %         \end{aligned}
        %     $$
        % \end{prop}
        % Using the identity that $\text{prox}_{f/\alpha} = \text{prox}_{f, \alpha}$, the proximal gradient is nonexpansive for all value of $\alpha$. 
        \begin{lemma}[Proximal Operator as Resolvant of Scaled Subgradient]\label{lemma:prox_alternative_form}
            When the function $f$ is convex closed and proper, the $\text{prox}_{\alpha, f}$ can be viewed as the following operator $(I + \alpha \partial f)^{-1}$, which is also, a single-valued operator that sometimes has a nice closed form solution to it.
        \end{lemma}
        \begin{proof}
            \begin{align*}
                0 &\in \partial
                \left[
                    \left.
                        f(y) + \frac{1}{2\alpha} \Vert y - x\Vert^2 
                    \right| y
                \right](y^+)
                \\
                0 &\in \partial f(y^+) + \frac{1}{\alpha}(y^+ - x)
                \\
                \frac{x}{\alpha} &\in 
                (\partial f + \alpha^{-1}I)(y^+)
                \\
                x &\in 
                (\alpha \partial f + I)(y^+)
                \\
                y &\in (\alpha\partial f+ I)^{-1}(x).
            \end{align*}
        \end{proof}
    \subsection{The Strong Smoothness}
        \begin{definition}[Strong Smoothness]\label{def:strong_smoothness}
            A differentiable function $g$ is called smooth with a constant $\alpha$ then it satisfies: 
            \begin{align}
                |g(y) - g(x) - 
                \langle \nabla g(x), y - x
                \rangle| \le \frac{\alpha}{2}\Vert x - y\Vert^2
                \quad \forall x, y\in \mathbb E. 
            \end{align}    
        \end{definition}
        The absolute value sign can be removed and replaced with $0\le$ when the function $g$ is a convex function.
        \begin{theorem}[Lipschiz Gradient and Strong Smoothness Equivalence Under Convexit]\label{thm:cvx_lipz_grad}
            Suppose $g$ is differentiable on the entire of $\mathbb E$. It is closed convex proper. It is strongly smooth with parameter $\alpha$ if and only if the gradient $\nabla g$ is globally Lipschitz continuous with a parameter of $\alpha$ and $g$ is closed and convex. 
        \end{theorem}
        \begin{proof}
            For conciseness, we skip the proof here. To convince, consider applying generalized Cauchy Inequality to (iv) in Theorem 5.8 for Beck's textbook \cite{paper:FISTA}. 
        \end{proof}
        
\section{Proximal Gradient and Forward Backward Envelope}\label{sec:pg_forward_backward_env}
    We introduce the algorithm through the forward-backward envelope; this helps with the intuitive understanding of this algorithm. We then state some of the essential properties. The forward-backward envelope name came from a numerical method that simulates a gradient system that is the summation of stiff and nonstiff dynamics by using forward Euler on the nonstiff part and backward Euler on the stiff part. We will not discuss this specific interpretation of the proximal gradient method. For more detail regarding this interpretation of the proximal gradient method, refers to Bloyd's paper \cite{paper:bloyd}. 
    \begin{assumption}[Convex Smooth Nonsmooth with Bounded Minimizers]\label{assumption:1}
        We will assume that $g:\mathbb E\mapsto \mathbb R$ is strongly smooth with constant $L_g$ and $h:\mathbb E \mapsto \bar{\mathbb R}$ is closed convex and proper. We define $f := g + h$ to be the summed function and $\text{ri}\circ \text{dom}(g) \cap \text{ri}\circ \text{dom}(h) \neq \emptyset$. We also assume that a set of minimizers exists for the function $f$ and that the set is bounded. Denote the minimizer using $\bar x$. 
    \end{assumption}
    
    \subsection{Proximal Gradient Minimizes the Forward Backward Envelope}
        First, we follow the intuitive idea of constructing an upper bounding function given a parameter $\beta$ as  $m_x(y|\beta)$; it can be interpreted as a surrogate function if one prefers for $g + h$ with $\beta \ge L_g$: 
        \begin{align*}
            & g(x) + h(x) \le 
            g(x) + \nabla g(x)^T(y - x) + \frac{\beta}{2} \Vert y - x\Vert^2
            + h(y) =: m_x(y|\beta) \quad \forall y \in \mathbb E, 
        \end{align*}
        this function $m_x(y|\beta)$ is a strongly convex function and it's equal to $g + h$ at $x$, and larger than it on every other points. The \emph{envelope function}, defined as $m^+(y|\beta):= \min_y \{m_x(y|\beta)\}$ minimizes the upper bounding function, and the function $m^+$ is lower than $g + h$ on all points and its minimizer takes the following form: 
        \begin{align*}
            \arg\min_{y} \{m_x(y)\} 
            = \arg\min_{y}\left\lbrace
                g(x) + \nabla g(x)^T(y - x) + \frac{\beta}{2}
                \Vert y - x\Vert^2 + h(y) 
            \right\rbrace. 
        \end{align*}
        
        \begin{theorem}[Minimizer of the Envelope]\label{thm:minimizer_envelope}
            The minimizer for the envelope has a closed form, and it is $\text{prox}_{h, \beta^{-1}}(x + \beta^{-1}\nabla g(x))$, with \hyperref[assumption:1]{assumption \ref*{assumption:1}}. 
        \end{theorem}
        \begin{proof}
            We consider minimizing the envelope; zero is in the subgradient of the upper bounding function $m_x(y|\beta)$. 
            \begin{align*}
                \mathbf 0 &\in 
                \nabla g(x) + {\beta}(y - x) + \partial h(y)
                \\
                \nabla g(x) + \beta x & \in
                \beta y + \partial h(y)
                \\
                -\beta^{-1} \nabla g(x) + x &\in y + \beta^{-1} \partial h(y)
                \\
                -\beta^{-1} \nabla g(x) + x &\in [I + \beta^{-1} \partial h](y)
                \\
                \implies
                [I + \beta^{-1}\partial h]^{-1}(- \beta^{-1} \nabla g(x) + x) 
                & \ni y,
            \end{align*}
            using \hyperref[lemma:prox_alternative_form]{lemma \ref*{lemma:prox_alternative_form}}, the RHS is the operator $\text{prox}_{h, \beta^{-1}}(x + \beta^{-1}\nabla g(x))$. 
        \end{proof}
        \begin{remark}
            The minimizer of the envelope at $x$: $\text{prox}_{h, \beta^{-1}}(x + \beta^{-1}\nabla g(x))$ is what we call \emph{prox step} for short, it makes the envelope $m_x(y|\beta)$ strictly lower than $f(x)$ for any point $x$ that is not the minimizer of $h + g$. 
        \end{remark}
    \subsection{Fixed Point of the Prox Step}\label{sec:fixed_point_prox}
        Denote the prox step $\mathcal P_{\beta^{-1}}^{g, h}(x) = \text{prox}_{h, \beta^{-1}}(x - \beta^{-1}\nabla g(x))$, in most context without ambiguity it will be denoted as $\mathcal Px$. The fixed point of $\mathcal P$ is a point $x$ such that $x = \mathcal P x$ if and only if $x$ is the minimizer of $f$ when \hyperref[assumption:1]{assumption \ref*{assumption:1}} is true. We denoted the fixed point as $\bar x$. To see how this is true consider any $x^+$ such that $x^+ = \mathcal Px$, using subgradient of the envelope: 
        \begin{align*}
            \mathbf 0 
            &\in \nabla g(x) + \beta(x^+ - x) + \partial h(x^+)
            \\
            \beta(x - x^+) &\in \partial h(x^+) + \nabla g(x^+)
            \\
            x = x^+ \iff \mathbf 0 &\in 
            \partial h(x^+) + \nabla g(x^+), 
        \end{align*}
        therefore, if $x^+$ is a fixed point of $\mathcal P$ if and only if it is one of the local minimizers of the function $f$. Conversely, if $x^+$ is not a fixed point of $x$, then it has to make the objective value of the upper bounding function $m_x(y| \beta)$ decrease because it is a strongly convex function. However, this does not necessarily mean that the prox step can decrease the value of the function $f$; more conditions are needed for the parameter $\beta$ to bound the value $f$ at the prox step point. We will explain more about this in the next subsection. 
        \begin{remark}
            The operator $\beta(x - \mathcal Px)$ is called the gradient mapping in Amiar's Book \cite{book:first_order_opt}, and it has many more critical properties that are useful for the convergence proof of the proximal gradient method under many different contexts. Please observe that if the function $h \equiv 0$, the gradient mapping is simply the gradient of the function $g$, which has a lot of favorable properties.
        \end{remark}
    \subsection{Step-Sizes that Ensures Monotone Descent Property}
        With \hyperref[assumption:1]{assumption \ref*{assumption:1}}, only a specific size of step-size can guarantee a decrease in the function value for the minimizers that minimize the envelope. For this section, we denote. 
        \begin{theorem}[Stepsize that Ensures Monotone Decrease]\label{thm:monotone_decrease}
            The step size $L^{-1}$ of the proximal gradient that guarantees a decrease in the objective value has to satisfy: $L \ge L_g$, where $L_g$ is the Lipschitz constant for the gradient of the function $g$ (recall \hyperref[thm:cvx_lipz_grad]{theorem \ref*{thm:cvx_lipz_grad}}) and $\mathcal Px$ is $\mathcal P_{L^{-1}}^{g, h}(x)$. 
        \end{theorem}
        \begin{proof}Consider the fact that the envelope at the prox step is smaller than the point where the envelope is touching with the function $f$ at $x$ (recall \hyperref[thm:minimizer_envelope]{theorem \ref*{thm:minimizer_envelope}}), we have $m_x(\mathcal Px|L_f)\le f(x)$ which gives: 
            \begin{align*}
                m_x(\mathcal Px|L) \le m_x(\mathcal Px|L_f) 
                &\le f(x)
                \\
                \implies h(\mathcal Px)+ 
                \langle \nabla g(x), \mathcal P x - x\rangle + \frac{L}{2}\Vert \mathcal Px - x\Vert^2 
                &\le h(x)
                \\
                h(\mathcal Px) - h(x) + \langle \nabla g(x) - \mathcal Px - x\rangle 
                &\le \frac{-L}{2} \Vert \mathcal Px - x\Vert^2, \tag{$\Delta$}
            \end{align*}
            next, we also consider the strongly smooth property of $g$ to obtain: 
            \begin{align*}
                g(\mathcal Px) - g(x) - \langle \nabla g(x), \mathcal Px - x\rangle 
                & \le \frac{L_g}{2}\Vert \mathcal Px - x\Vert^2 \tag{$\nabla$}
                \\
                \implies
                h(\mathcal Px) + g(\mathcal Px) - g(x) - h(x)
                &\le 
                \left(
                    \frac{L_g}{2} - \frac{L}{2}
                \right)\Vert \mathcal Px - x\Vert^2 \tag{**}
                \\
                f(\mathcal Px) - f(x) 
                &\le
                \left(
                    \frac{L_g}{2} - \frac{L}{2}
                \right)\Vert \mathcal Px - x\Vert^2, 
            \end{align*}
            where (**) is $(\nabla) + (\Delta)$. Observe that the objective decrease is asserted on the last line if $L_g \le L$. Additionally, using \hyperref[thm:minimizer_envelope]{theorem \ref*{thm:minimizer_envelope}}, we have $L^{-1}$ being the step sizes inside of the proximal gradient operator. See Beck's paper \cite{paper:FISTA} for more details about line search conditions employed for the proximal gradient algorithm.
        \end{proof}
        \begin{remark}
            The monotone decrease property of step size is useful for engineering the backtracking routine for the proximal gradient method. More specifically, as long as the step size $L^{-1}$ satisfies $m_x(\mathcal Px | L)\le f(x)$, then it's an acceptable step size. 
        \end{remark}
    \subsection{Proximal Gradient Algorithm}
        \begin{algorithm}[H]
            \begin{algorithmic}[1]
            \STATE{\textbf{Input:} $g, h$, smooth and nonsmooth, $L$ stepsize, $x^{(0)}$ an initial guess of solution. }
            \FOR{$k=1, 2,\cdots, N$}
                \STATE{\quad $x^{(k + 1)} = \mathcal P_L^{g, h}x^{(k)}$}
                \IF{$x^{(k + 1)}, x^{(k)}$ close enough}
                    \STATE{\textbf{Break}}
                \ENDIF
            \ENDFOR
            \end{algorithmic}
            \caption{Proximal Gradient With Fixed Step-sizes}
            \label{alg:1}
        \end{algorithm}
        \begin{remark}
            The \hyperref[alg:1]{Proximal Gradient With Fixed Step Size} algorithm terminates either it reaches the iteration limit $N$ or the fixed point iterations on the operator $\mathcal P$ have converged. In some cases, we can obtain the Lipschitz constant for $g$ in advance; in other cases, it is not easy to obtain. 
        \end{remark}

\section{Convergence of Proximal Gradient}\label{sec:pg_convergence}
    Here, we give analysis for the convergence behaviors of the algorithm in \hyperref[alg:1]{\ref*{alg:1}} with fixed stepsizes and assumption \hyperref[assumption:1]{\ref*{assumption:1}} is true. 
    \subsection{Convergence Under the Convex Case}
        Before the proof, we state some of the quantities that are involved in the proof. 
        \begin{enumerate}
            \item [1.] Recall from \hyperref[sec:fixed_point_prox]{section \ref*{sec:fixed_point_prox}} where $G_\beta(x) - \nabla g(x) \in \partial h(x^+)$ with $x^+ \in \mathcal P_{\beta^{-1}}^{g, h}(x)$, and this general condition is true for all values of $x$. We refer to $G_\beta(x)$ as the residual of the proximal gradient algorithm. Finally, $G_\beta(x) = \beta(x - x^+)$
            \item [2.] By choosing the stepsize $\beta^{-1} \le L^{-1}$, we assert a strict decrease of the value of the objective function, $f(x^+) \le f(x)$. 
            \item [3.] We denote $\bar f$ to be $f(\bar x)$ where $\bar x$ is one of the minimizers of $f$. 
        \end{enumerate}
        \begin{theorem}[Convergence Under Convexity]\label{thm:convergence_non_accelerated}
            With \hyperref[assumption:1]{assumption \ref*{assumption:1}}, execute the algorithm for $N$ steps, we have: 
            \begin{align*}
                f(x^{(N + 1)}) - \bar f
                &\le  
                \frac{\beta(\Vert x^{(0)} - \bar x\Vert^2 - \Vert x^{(N + 1)} - \bar x\Vert^2)}{2(N + 1)}. 
            \end{align*}
        \end{theorem}
        \begin{proof}
            This proof is standard and does not entirely resemble the proof showed in \cite[Aimir, Teboulle]{paper:FISTA}; nonetheless, we will extract a lemma out of this proof and use that as the foundation for the proof in the Nesterov Accelerated case of the proximal gradient algorithm.  
            \par
            Firstly by choice of step size and the strong smoothness of the function $g$, we have the inequality: 
            \begin{align*}
                g(x^+) 
                & \le 
                g(x) - \beta^{-1}\langle \nabla g(x), G_\beta(x)\rangle + \underbrace{\frac{L}{2\beta^2}\Vert G_\beta(x)\Vert^2}_
                {
                    \le \frac{1}{2\beta}\Vert G_\beta(x)\Vert^2
                }, \tag{*}
            \end{align*}
            next, by the convexity of $f, g$, we have inequalities: 
            \begin{align*}
                & g(x) \le g(z) - \langle \nabla g(x), x - z\rangle
                \\
                & h(x^+)\le h(z) + \langle \partial h(x^+), x^+ - z\rangle, 
            \end{align*}
            where we abuse the notation $\partial h(x^+)$ to denote some vector in the subgradient of $h$ at point $x^+$. Next, we substitute the above results into (*): 
            \begin{align*}
                g(x^+) + h(x^+) 
                & \le 
                g(x) + \beta^{-1}\langle \nabla g(x), G_\beta(x)\rangle + \frac{1}{2\beta}\Vert G_\beta(x)\Vert^2 + h(x^+) 
                \\
                & \le 
                g(z) + 
                \underbrace{\langle \nabla g(x), x - z\rangle }_{[1]}
                - 
                \underbrace{\beta^{-1}\langle \nabla g(x), G_\beta(x)\rangle}_{[2]}
                \\& \quad \quad 
                + 
                \frac{1}{2\beta}\Vert G_\beta(x)\Vert^2 + h(z) + 
                \underbrace{\langle \partial h(x^+), x^+ - z\rangle}_{[4]}, 
                \tag{$\nabla$}
            \end{align*}
            and we consider the summation for each of these numerically labeled terms to obtain
            \begin{align*}
                {[3]}& := [1] + [2]
                \\
                [3] &= \langle \nabla g(x), x - z - x + x^+\rangle = \langle \nabla g(x), x^+ - z\rangle
                \\
                [3] + [4] &= 
                \langle \nabla g(x), x^+ - z\rangle + \langle G_\beta(x) - \nabla g(x), x^+ - z\rangle \tag{**}
                \\
                &= \langle G_\beta(x), x^+ - z\rangle 
                \\
                &= \langle G_\beta(x), x - z - (x - x^+)\rangle
                \\
                &= \langle G_\beta, x - z\rangle - \langle G_\beta, \underbrace{x - x^+}_{ = \beta^{-1}G_\beta(x)}\rangle
                \\
                &= \langle G_\beta(x), x - z\rangle - \beta^{-1}\Vert G_\beta(x)\Vert^2, 
            \end{align*}
            where at (*) we applied the substitution $G_\beta (x) - \nabla f(x)\in \partial h(x^+)$. 
            Comtinued from ($\nabla$) we obtain 
            \begin{align*}
                \underbrace{g(x^+) + h(x^+)}_{f(x^+)}
                & \le 
                \underbrace{g(z) + h(z)}_{f(x)} - \frac{1}{2\beta}\Vert G_\beta(x)\Vert^2 + \langle G_\beta, x - z\rangle
                \\
                f(x^+) - f(z) 
                &\le 
                \langle G_\beta(x), x - z\rangle - \frac{1}{2\beta}\Vert G_\beta(x)\Vert^2. \tag{$\star$}
            \end{align*}
            Next, we make the simplifications using algebra and get
            \begin{align*}
                f(x^+) - f(\bar x) 
                &\le 
                \frac{-1}{2\beta}\Vert G_\beta(x)\Vert^2
                + 
                \langle G_\beta, x - \bar x\rangle
                \\
                &= 
                -\frac{\beta}{2}(
                    \Vert x - x^+\Vert^2 - 2\langle x - x^+, x - \bar x\rangle
                )
                \\
                [5]
                \implies &= 
                \frac{-\beta}{2}(
                    \Vert x^+ - \bar x\Vert^2
                    - 
                    \Vert x - \bar x\Vert^2
                )
                \\
                &= 
                \frac{\beta}{2}(\Vert x - \bar x\Vert^2 - \Vert x^+ - \bar x\Vert^2), 
            \end{align*}
            and since the step-size assert a non-decreasing sequence of number, we perform the telescoping sum by considering the substitution $x^+ = x^{(k + 1)}, x = x^{(k)}$ we get: 
            \begin{align*}
                f(x^{(k + 1)}) - \bar f 
                &\le
                \frac{\beta}{2}(\Vert x^{(k)} - \bar x\Vert^2 - \Vert x^{(k + 1)} - \bar x\Vert^2)
                \\
                \implies
                \left(
                    \sum_{i = 0}^{N} f(x^{(i + 1)})
                    - \bar f
                \right)
                &\le
                \frac{\beta}{2}
                (\Vert x^{(0)} - \bar x\Vert^2 - \Vert x^{(N + 1)} - \bar x\Vert^2)
                \\
                f(x^{(N + 1)}) - \bar f & = 
                \min_{i = 0, \cdots, N}\left\lbrace
                    f(x^{(i + 1)}) - \bar f
                \right\rbrace \le 
                \left(
                    \frac{1}{N + 1}\sum_{i = 0}^{N}f(x^{(i + 1)})
                \right) - \bar f
                \\
                \implies
                f(x^{(N + 1)}) - \bar f
                &\le  
                \frac{\beta(\Vert x^{(0)} - \bar x\Vert^2 - \Vert x^{(N + 1)} - \bar x\Vert^2)}{2(N + 1)}
                \\
                &\le 
                \frac{\beta \Vert x^{(0)} - \bar x\Vert^2 }{2(N + 1)}. 
            \end{align*}
        \end{proof}
        \begin{remark}
            One important lemma that we can extract from this proof will later be important for the proof of the accelerated case. The tagged expression ($\star$) in the above derivation. We will refer to this as the ``Prox Step 2 Points" lemma. Expression $(\star)$ is equivalent to the lemma 2.3 in the FISTA paper\cite{paper:FISTA}. 
        \end{remark}
        \begin{lemma}[Prox Step 2 Points]\label{lemma:prox_two_p}
            With \hyperref[assumption:1]{assumption \ref*{assumption:1}}, and $\beta^{-1} > L_g$ still being our stepsize for \hyperref[alg:1]{algorithm \ref*{alg:1}}, let $y\in \mathbb E$ and define $y^+ = \mathcal P_{\beta^{-1}}^{g, h}(y)$ we have for any $x\in \mathbb E$: 
            \begin{align*}
                f(x) - f(y^+) \ge \frac{\beta}{2}\Vert y^+ - y\Vert^2 + 
                \beta \langle y - x, y^+ - y\rangle. 
            \end{align*}
        \end{lemma}
        \begin{proof}
            The proof is continuted from expression $(\star)$: 
            \begin{align*}
                f(x^+) - f(z) 
                &\le 
                \langle G_\beta(x), x - z\rangle - \frac{1}{2\beta}\Vert G_\beta(x)\Vert^2. 
                \\
                f(x^+) - f(z) & \le 
                \beta\langle x - x^+, x - z\rangle - \frac{1}{2\beta}\Vert \beta (x - x^+)\Vert^2
                \\
                f(z) - f(x^+) & \ge
                \frac{\beta}{2}\Vert x - x^+\Vert^2
                 + 
                \beta\langle x^+ - x, x - z\rangle, 
            \end{align*}
            and by substituting $x:=y$ and $z:= x$ in the last line, we completed the proof of the lemma. 
        \end{proof}

\section{Accelerated Proximal Gradient}\label{sec:apg_intro}
    Here we state the Accelerated Proximal algorithm in Beck's Paper paper\cite{paper:FISTA} and prove the convergence. The convergence proof follows what is in the paper but with more details in the appendix. The FISTA algorithm stands for Fast Iterative Shrinkage-Thresholding Algorithm, which is the specific case of the Proximal Gradient with Nesterive momentum applied to the LASSO problem. FISTA is an accelerated case of the ISTA algorithm, and it is the same as FISTA but without the Nesterov momentum. 
    
    \subsection{Accelerated Proximal Gradient Algorithm} 
        \begin{algorithm}[H]\label{alg:fista_1} 
        \begin{algorithmic}[1]
            \STATE{\textbf{Input: the step size $\beta^{-1}$, and $x^{(0)}$ the initial guess. } }
            \STATE{$y^{(1)} = x^{(0)}$}
            \FOR{$k=1, \cdots, N$}
                \STATE{$x^{(k)}:= \mathcal Py^{(k)}$}
                \IF{$y^{(k)} - x^{(k)}$ small enough}
                    \STATE{Break}
                \ENDIF
                \STATE{$t_{k + 1} := \frac{1 + \sqrt{1 + 4t_k^2}}{2}$}
                \STATE{$y^{(k + 1)}:= x^{(k)} + \frac{t_k -1}{t_{k + 1}}(x^{(k)} - x^{(k - 1)})$}
            \ENDFOR
        \end{algorithmic}\caption{FISTA With Constant Step Size}
        \end{algorithm}

    \subsection{Convergence Under the Convex Case}
        \begin{theorem}[FISTA Convergence under Convexity]\label{thm:fista_convergence1}
            If \hyperref[assumption:1]{assumption \ref*{assumption:1}} is satisfied, then the FISTA algorithm has convergence result of: 
            \begin{align*}
                f(x^{(k)}) - f(\bar x) \le 
                \frac{2\beta^{-1}\Vert x^{(0)} - \bar x\Vert^2}
            {(k + 1)^2},
            \end{align*}
            where $\bar x$ is one of the optimizers, the convergence rate is $\mathcal O(1/k^2)$. 
        \end{theorem}
        \begin{proof}
            For a proof see \hyperref[sec:fista1_proof]{appendix \ref*{sec:fista1_proof}}
        \end{proof}

\section{Numerical Experiments}\label{sec:numerical_experiments}
    This section uses a simple LASSO algorithm to demonstrate convergence. We demonstrate a bigger application of image deblurring with noises using the FISTA algorithm. 
    \subsection*{Simple LASSO}
        As the name suggested, we consider the overuse example problem of: 
        \begin{align*}
            \min_{x}\left\lbrace
                \frac{1}{2}\Vert Ax - b\Vert^2_2 + \lambda\Vert x\Vert_1    
            \right\rbrace
        \end{align*}
        For a brief background, this problem appears in the context of regression for a generalized linear model where we want sparse coefficients on the regression parameters. Theoretically, it corresponds to having a prior Laplace distribution for the regression parameters (See 11.4.1 in Murphy's\cite{book:ml_prob_murphy} book for more details.). The implementation is simple, and the proximal gradient oracle for $\Vert \cdot \Vert_1$ is given as: 
        \begin{align*}
           (\text{prox}_{\lambda\Vert \cdot \Vert, t}(x))_i
           = 
           \text{sign}(x_i)\max(|x_i| - t\lambda, 0), 
        \end{align*}
        which can be interpreted the $\text{sign}$ function as the projection onto the interval $[-1, 1]$, and the $\max(|x| - t\lambda, 0)$ as the distance of $x$ to the set $[-t\lambda, t\lambda]$. The quantity $t$ is the stepsize in the proximal gradient method, which is less than the reciprocal of the maximum absolute eigenvalue of $A^TA$. 
        \par
        For this simple lasso problem, we make $A$ a diagonal 128 by 128 matrix, whose diagonals are points equally spaced in the interval $[0, 2]$. Observe that this is quadratic but not strongly convex. The right-hand side vector $b$ is the same as the diagonal of matrix $A$, but with every odd index replaced with a gaussian random noise on the level of $1^{-3}$. we performed the experiment with both ISTA and FISTA with $\lambda = 10^{-2}$. We use a step size of $0.2$ for both (It is there to prevent triggering the line search routine in the implementation). The initial guess vector $x^{(0)}$ is a vector of 3, which is the same for both FISTA and ISTA. 
        \par
        For the experiment, we record and present the objective values $f$ for each of the iterations and the norm of the proximal mapping $\Vert x^{(k + 1)} - x^{(k)}\Vert_\infty$ in the none accelerated case and $\Vert y^{(k)} - x^{(k + 1)}\Vert_\infty$ in the accelerated case for each iteration. See \hyperref[fig:lasso_1]{figure \ref*{fig:lasso_1}} for an illustration. Both algorithms terminate whenever the norm of the proximal gradient mapping is less than $10^{-10}$ during the iteration. We plotted the norm on a log scale. Observe that the type of convergence for FISTA is very different compared to the ISTA case. In the case of ISTA, the norm of the proximal mapping on the log plot resemble a curve at the start and quickly changes its behaviors in the later iterations. The convergence of iteration after 2000 is a straight line. This phenomenon indicates first-order convergence for ISTA. In FISTA, the overall convergence rate is slower than ISTA for 2000 iterations, and then it starts to slow down; nonetheless, it converges faster. We plot the objective value on the left of \hyperref[fig:lasso_1]{figure \ref*{fig:lasso_1}}; the plot is on a log scale too. The optimal value $f(\bar x)$ is assumed to be whenever the gradient mapping has a norm within $10^{-10}$. Observe that FISTA already reaches the optimal around 476 iterations, disregarding that the norm of the gradient mapping is not within the tolerance. 
        \begin{figure}[h]
            \centering
            \includegraphics*[width=8cm]{simple_lass_obj.png}
                \includegraphics*[width=8cm]{simple_lass_pgrad.png}
            \caption{The left is the objective value of the function during all iterations, and the right side is the norm of the gradient mapping for all the iterations. }
            \label{fig:lasso_1}
        \end{figure}
        \begin{remark}
            The convergence rate of the optimality gap is linear when the smooth function $g$ is strongly convex; see theorem 10.29 of Beck's book\cite{book:first_order_opt} for the linear convergence of proximal gradient without acceleration. There are variants of FISTA, for example, the Restarted FISTA. Beck's book, Theorem 10.41 \cite{book:first_order_opt} discusses their convergence behaviors.
        \end{remark}
        
    \subsection*{Image Deblurring}
        We reproduced some of the experiments conducted in Beck's FISTA paper \cite{paper:FISTA} but using larger images with colors. We consider a cartoon image of a pink unicorn (I own the image) of 500 by 500 pixels, 3 color channels, blurred. The matrix $A$ does the blurring. It is performing a convolution using discretized $15\times 15$ pixels gaussian kernel with a variance of $4$ on all pixels with a periodic boundary condition across all color channels independently. The implementation for $A$ is a for loop that constructs a sparse matrix $A$. The 750000 by 750000 sparse matrix $A$ acts independently on the vectorized image across all three color channels. More efficient ways exist, such as using the Kronecker product. However, for the sake of demonstration, the alternatives are unexplored because the explicit $A$ matrix allows us to reuse the code that made the previous demonstration. 
        \par
        The vector $b = Ax^+ + \epsilon$ where $x^+$ is the flattened array of the original image of all three color channels normalized to $[0, 1]$ using float64. The quantity $\epsilon$ is a zero mean gaussian noise vector with zero mean and variance of 2e-2. Here we define $\lambda = \alpha\times (3\times500^2)^{-1}$, and we make 3 experiments with $\alpha = 0, 0.01, 0.1$. The initial guess vector $x^{(0)}$ is a random zero mean gaussian vector of unit variance. The blurred image is showed in \hyperref[fig:blurred_alto]{figure \ref*{fig:blurred_alto}}. Moreover, the results of the deblurring algorithm for different value of $\alpha$ is shown in \hyperref[fig:alto_deblurred]{figure \ref*{fig:alto_deblurred}}, observes that with $\lambda = 0$, the solution contains much noise. However, just a tiny amount of $\lambda$ prevents the noises on the black background on the recovered image. 
        \begin{figure}[H]
            \centering
            \includegraphics*[width=5cm]{blurred_img.jpg}
            \caption{The image is blurred by the Gaussian Blurred matrix $A$ with a tiny amount of noise on the level of 2e-2 that is barely observable. Zoom in to observe the tiny amount of Gaussian noise on top of the blur.}
            \label{fig:blurred_alto}
        \end{figure}
        \begin{figure}[H]
            \centering
            \begin{subfigure}{0.31\textwidth}
                \includegraphics[width=5cm]{inverse_linear_experiment1-soln_img.jpg}
                \caption{} \label{fig:1a}
            \end{subfigure}     %
            \hspace*{\fill}     % maximize separation between the subfigures
            \begin{subfigure}{0.31\textwidth}
                \includegraphics[width=5cm]{inverse_linear_experiment2-soln_img.jpg}
                \caption{} \label{fig:1b}
            \end{subfigure}     %
            \hspace*{\fill}     % maximize separation between the subfigures
            \begin{subfigure}{0.31\textwidth}
                \includegraphics[width=5cm]{inverse_linear_experiment3-soln_img.jpg}
                \caption{} \label{fig:1c}
            \end{subfigure}
            \caption{(a) $\alpha = 0$, without any one norm penalty, is not robust to the additional noise. (b) $\alpha = 0.01$, there is a tiny amount of $\lambda$. (c) $\alpha = 0.1$, it is more penalty compared to (a).}
            \label{fig:alto_deblurred}
        \end{figure}


\appendix
% \begin{section}{Proof for Convergence of FISTA}\label{sec:fista1_proof}
%     Here we prove \hyperref[thm:fista_convergence1]{theorem \ref*{thm:fista_convergence1}}. The proof closely follows Beck and Teboulle's work \cite{paper:FISTA}, and here we prove everything with extra details. 
%     \begin{subsection}{The First Lemma}
%         Recall from \hyperref[lemma:prox_two_p]{lemma \ref*{lemma:prox_two_p}}
%         and \hyperref[assumption:1]{assumption \ref*{assumption:1}}, instead of using $\beta^{-1}$ as our step size we use $L$. Here we introduce the notation $\delta_k = f(x^{(k)}) - f(\bar x)$ to denote the optimality gap at the $k$ iteration of the algorithm where $\bar x$ denotes one of the minimizer of the function $f$. 
%         \begin{lemma}[FISTA First Lemma]\label{lemma:fista_first_lemma}
%             The optimality gap generated via FISTA statisfies: 
%             \begin{align*}
%                 & 
%                 \frac{2}{L}t^2_k \Delta_k - \frac{2}{L}t^2_{k + 1} \Delta_{k + 1} 
%                 \ge 
%                 \Vert u^{(k + 1)}\Vert^2 - \Vert u^{(k)}\Vert^2
%                 \\
%                 & \Delta_k := f(x^{(k)}) - f(\bar x)
%                 \\
%                 & u^{(k)} := t_k x^{(k)} - (t_k - 1)x^{(k - 1)} - \bar x.
%             \end{align*}
%         \end{lemma}
%         \begin{proof}
%             We invoke the \hyperref[lemma:prox_two_p]{lemma \ref*{lemma:prox_two_p}} with $x = x^{(k)}, y = y^{(k +1)}$ to give: 
%             \begin{align*}\label{lemma:fista_first_lemma_1}
%                 f(x^{(k)}) - f\circ \mathcal P y^{(k + 1)}
%                 & \ge 
%                 \frac{L}{2}\Vert \mathcal Py^{(k + 1)} - y^{(k + 1)}\Vert^2 + 
%                 L \langle y^{(k + 1)} - x^{(k)}, 
%                     \mathcal Py^{(k + 1)} - y^{(k + 1)}
%                 \rangle
%                 \\
%                 f(x^{(k)}) - f(x^{(k + 1)}) 
%                 & \ge 
%                 \frac{L}{2}\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2 + 
%                 L 
%                 \langle 
%                     y^{(k + 1)} - x^{(k)}, 
%                     x^{(k + 1)} - y^{(k + 1)}
%                 \rangle, 
%                 \\
%                 \implies
%                 2L^{-1} (\Delta_k - \Delta_{k + 1}) 
%                 & \ge 
%                 \Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2 + 
%                 2\langle x^{(k + 1)} - y^{(k + 1)}, y^{(k + 1)} - x^{(k)}\rangle. 
%                 \tag{$*$}
%             \end{align*}
%             Observe that from the first line to the second line we invoke the definition for the updates for $x^{(k)}$ in the \hyperref[alg:fista_1]{FISTA Algorithm}. We then invoke the lemma again with $x:= \bar x, y = y^{(k + 1)}$, and it gives us: 
%             \begin{align*}
%                 f(\bar x) - f\circ \mathcal P y^{(k + 1)}
%                 & \ge 
%                 \frac{L}{2}\Vert \mathcal P y^{(k + 1)} - y^{(k + 1)}\Vert^2 
%                 + L 
%                 \langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle
%                 \\
%                 f(\bar x) - f(x^{(k + 1)}) 
%                 &\ge 
%                 \frac{L}{2}\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
%                 + 
%                 L \langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle
%                 \\
%                 -2L^{-1}\Delta_{k + 1}
%                 & \ge
%                 \Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
%                 + 
%                 2\langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle. 
%                 \tag{$\star$}
%             \end{align*}
%             Consider the expression $(t_k - 1)(*) + (\star)$, we obtain the LHS of that expression: 
%             \begin{align*}
%                 &(t_{k + 1} - 1)L^{-1} (\Delta_k - \Delta_{k + 1}) 
%                 -
%                 2L^{-1}\Delta_{k + 1}
%                 \\
%                 = \; &
%                 2L^{-1}
%                 ((t_{k + 1} + 1)\Delta_k - (t_{k + 1} - 1)\Delta_{k + 1} - \Delta_{k + 1})
%                 \\
%                 = \; &
%                 2L^{-1}((t_{k + 1} - 1)\Delta_k - t_{k + 1}\Delta_{k + 1}),
%                 \tag{$\star *$LHS}
%             \end{align*}
%             and then the RHS is: 
%             \begin{align*}
%                 & (t_{k + 1} - 1)\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
%                 + 
%                 2(t_{k + 1} - 1)\langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle 
%                 \\
%                 & \quad 
%                 + \Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
%                 + 
%                 2\langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle
%                 \\
%                 = \; &
%                 t_{k + 1}\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
%                 + 
%                 \langle 
%                     x^{(k + 1)} - y^{(k + 1)}, 
%                     \underbrace{2(t_{k + 1} - 1)(y^{(k + 1)} - x^{(k)}) + 2(y^{(k + 1)} - \bar x) }_
%                     {
%                         = 2(t_{k + 1}y^{(k + 1)} + (1 - t_{k + 1})x^{(k)} - \bar x)
%                     }
%                 \rangle
%                 \\
%                 = \; & 
%                 t_{k + 1}\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
%                 + 
%                 2\langle 
%                     x^{(k + 1)} - y^{(k + 1)}, 
%                     t_{k + 1}y^{(k + 1)} + (1 - t_{k + 1})x^{(k)} - \bar x
%                 \rangle. 
%                 \tag{$\star *$RHS}
%             \end{align*}
%             The entirety of expression (3) is given by: 
%             \begin{align*}
%                 & 2L^{-1}((t_{k + 1} - 1)\Delta_k - t_{k + 1}\Delta_{k + 1})
%                 \ge 
%                 t_{k + 1}\Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2
%                 \\
%                 & \quad 
%                 + 
%                 2\langle 
%                     x^{(k + 1)} - y^{(k + 1)}, 
%                     t_{k + 1}y^{(k + 1)} + (1 - t_{k + 1})x^{(k)} - \bar x
%                 \rangle. 
%                 \tag{$\star *$}
%             \end{align*}
%             The next part of the proof shows some of the magics involves in changing the LHS,RHS of $(\star *)$ to be the similar to what is in the theorem statement. It's accomplished by the relations for the sequence $t_k$, more specifically it's hinged on the relations $t_k^2 = t^2_{k + 1} - t_{k + 1}$ which is asserted by the FISTA algorithm. Using this fact we proceed by multiplying $t_{k + 1}$ on both sides of $(\star *)$ and obtain: 
%             \begin{align*}
%                 & 2L^{-1}(\Delta_k t_k^2 - \Delta_{k + 1}t_{k + 1}^2)
%                 \\
%                 & \hspace{2em}
%                 \begin{aligned}
%                     & \ge 
%                     \Vert t_{k + 1}(x^{(k + 1)} - y^{(k + 1)})\Vert^2 - 
%                     2\langle 
%                         t_{k + 1}(x^{(k + 1)} - y^{(k + 1)}), 
%                         t_{k + 1}y^{(k + 1)} - 
%                         (t_{k + 1} - 1)x^{(k)} - \bar x
%                     \rangle
%                 \end{aligned}
%                 \\
%                 & 2L^{-1}(\Delta_k t_k^2 - \Delta_{k + 1}t_{k + 1}^2)
%                 \\ 
%                 &\hspace{2em}
%                 \begin{aligned}
%                     & \ge 
%                     \Vert 
%                         \underbrace{t_{k + 1}x^{(k + 1)}}_{
%                             =:a
%                         } - \underbrace{t_{k + 1}y^{(k + 1)}}_{
%                             =:b
%                         }
%                     \Vert^2 
%                     - 
%                     2\langle 
%                     \underbrace{ t_{k + 1}x^{(k + 1)}}_{=:a} - t_{k + 1}y^{(k + 1)}, 
%                         \underbrace{t_{k + 1}y^{(k + 1)}}_{=:b} - 
%                         \underbrace{((t_{k + 1} - 1)x^{(k)} + \bar x)}_{=:c}
%                     \rangle
%                     \\
%                     & \ge 
%                     \Vert a - b\Vert^2 + 2\langle a - b, b -c\rangle
%                     \\
%                     & = 
%                     \Vert a - b\Vert^2 + \Vert b - c\Vert^2 + 
%                     2\langle a-b, b -c\rangle - \Vert b - c\Vert^2
%                     \\
%                     &= 
%                     \Vert a - c\Vert^2 - \Vert b - c\Vert^2
%                     \\
%                     &\ge 
%                     \Vert 
%                         t_{k+ 1}x^{(k + 1)} - 
%                         (t_{k + 1} - 1)x_k - \bar x 
%                     \Vert^2 - 
%                     \Vert 
%                         (t_{k + 1} - 1)x^{(k)} - t_{k + 1}y^{(k + 1)}
%                         - \bar x
%                     \Vert^2, 
%                 \end{aligned}
%             \end{align*}
%             to prove the lemma, we need to match the form in the above 2 norm of the vector, we accomplish this by considering FISTA algorithm: 
%             \begin{align*}
%                 t_{k + 1}y^{(k + 1)} &= t_{k + 1}x^{(k)} + (t_k - 1)(x^{(k)} - x^{(k - 1)})
%                 \\
%                 t_{k + 1}y^{(k + 1)} - (t_{k + 1}- 1)x^{(k)}
%                 &= t_{k + 1}x^{(k)} - (t_{k + 1}- 1)x^{(k)} + (t_k - 1)(x^{(k)} - x^{(k - 1)})
%                 \\
%                 &= 
%                 x^{(k)} + (t_k - 1)x^{(k)} - (t_k - 1)x^{(k - 1)}
%                 \\
%                 &= t_kx^{(k)} - (t_k - 1)x^{(k - 1)}, 
%             \end{align*}
%             cf from previously we have: 
%             \begin{align*}
%                 & 2L^{-1}(\Delta_k t_k^2 - \Delta_{k + 1}t_{k + 1}^2)
%                 \\
%                 &\ge 
%                 \Vert 
%                     t_{k + 1}x^{(k + 1)}
%                     + 
%                     (1 - t_{k + 1}) x^{(k)} - \bar x
%                 \Vert^2
%                 - 
%                 \Vert t_kx^{(k)} + (1 - t_k)x^{(k -1)} - \bar x\Vert^2
%                 \\
%                 & \ge \Vert u^{(k + 1)}\Vert^2 - \Vert u^{(k)}\Vert^2.
%             \end{align*}
%             And that completes the proof of the Second Lemma. 
%         \end{proof}
%         \begin{remark}
%             There should be some point, where we can infer the properties of the sequence $t_k$ instead of taking the sequence from FISTA algorithm for granted, there should also be a way to make a different decision during the proof so that this becomes the proof for the algorithm without the accelerations technique. 
%         \end{remark}
%     \end{subsection}

%     \begin{subsection}{The Second Lemma}
%         \begin{lemma}[FISTA Second Lemma]
%             Let $\{a, b\}$ be positive real numbers sequence satisfying: $a_k - a_{k - 1}\ge b_{k + 1} - b_k, \forall k \ge 1$, with $a_1 + b_1 \le c, c > 0$, and then it would mean that $a_{k + 1}\le c$. 
%         \end{lemma}
%         \begin{proof}
%             The base case of the proof is obvious by the fact that $b_1$ is positive, hence $a_1 \le c$ is true. the relation automatically holds true for all $k\ge 1$ because $a_k - a_{k + 1}\ge b_{k + 1} - b_k \implies a_k + b_k \le c$, then $a_k - a_{k + 1}\ge b_{k + 1} - b_k \implies a_k + b_k \le a_{k + 1} + b_{k + 1} \implies a_{k + 1} + b_{k + 1} \le c\implies a_{k + 1}\le c$. 
%         \end{proof}
%     \end{subsection}

%     \begin{subsection}{The Third Lemma}
%         \begin{lemma}[FISTA Third Lemma]
%             The FISTA asserts $t_k \ge (k + 1)/2, \forall k \ge 1$. 
%         \end{lemma}
%         \begin{align*}
%             t_k 
%             &\ge \frac{k + 1}{2}
%             \\
%             4t_k^2 
%             &\ge 4\left(
%                 \frac{k + 1}{2}
%             \right)^2
%             \\
%             \implies 
%             t_k &= \frac{1}{2}\left(
%                 1 + \sqrt{1 + 4t_k^2}
%             \right)
%             \\
%             &= 
%             \frac{1}{2} + \frac{\sqrt{1 + (k + 1)^2}}{2}
%             \\
%             & \ge \frac{1 + k}{2}, 
%         \end{align*}
%     \end{subsection}
%     \subsection{Convergence Proof}
%         Firstly we define the quantities: 
%         \begin{itemize}
%             \item [1.] $a_k := (2/L)t_k^2 \Delta_k$.
%             \item [2.] $b_k := \Vert u^{(k)}\Vert^2$.
%             \item [3.] $c:= \Vert x^{(0)} - \bar x\Vert^2 = \Vert y^{(1)} - \bar x\Vert^2$. 
%         \end{itemize}
%         Recall from the first lemma, and we can represents it using the quantities listed above: 
%         \begin{align*}
%             2L^{-1}(\Delta_kt_k^2 - \Delta_{t + 1}t_{k + 1}^2) 
%             &\ge 
%             \Vert u^{(k + 1)}\Vert^2 - \Vert u^{(k)}\Vert^2
%             \\
%             a_k - a_{k + 1} &\ge 
%             b_{k + 1} - b_k, 
%         \end{align*}
%         To demonstrate how the base case hold up for the second lamma, we consider \hyperref[lemma:prox_two_p]{lemma \ref*{lemma:prox_two_p}}, substituting $x^{(1)}$ for $x$ and $\bar x$ for $y$, implicitly using the fact that $\bar x$ is a fixed point of $\mathcal P$: 
%         \begin{align*}
%             \Delta_1& \ge 
%             \frac{L}{2}\Vert \mathcal Py^{(1)} - y^{(1)}\Vert^2 + L 
%             \langle y^{(1)} - \bar x, \mathcal P y^{(1)} - y^{(1)}\rangle
%             \\
%             & =
%             \frac{L}{2}\Vert \mathcal P x^{(1)} - y^{(1)}\Vert^2 + L 
%             \langle x^{(1)} - \bar x, x^{(1)} - y^{(1)}\rangle
%             \\
%             &= 
%             \frac{L}{2}
%             (\Vert x^{(1)} - \bar x\Vert^2 - \Vert y^{(1)} - \bar x\Vert^2)
%             \\
%             \implies
%             2L^{-1}\Delta_1 
%             &\le
%             \underbrace{\Vert y^{(1)} - \bar x\Vert^2}_{=c} - \Vert x^{(1)} - \bar x\Vert^2
%             \\
%             \implies
%             a_1 + b_1
%             & \le c, 
%         \end{align*}
%         using the fact that $t_1 = 1$ we have $u^{(1)} = x^{(1)} - \bar x \implies b_1 = \Vert x^{(1)} - \bar x\Vert^2$, please observe that the above expression simplifies to $a_1 + b_1 \le c$. Invoking the second lemma, we have the claim that $a_{k + 1}\le c$, which is stated as: 
%         \begin{align*}
%             2L^{-1}t_{k + 1}^2\Delta_{k + 1} 
%             &\le \Vert x^{(0)} - \bar x\Vert^2
%             \\
%             \implies
%             \Delta_{k + 1}
%             &\le 
%             \frac{L\Vert x^{(0)} - \bar x\Vert^2}{2t_k^2}
%             \\
%             & \le 
%             \frac{L\Vert x^{(0)} - \bar x\Vert^2}{2 \times 2^{-2}(k + 1)^2}
%             = 
%             \frac{2L\Vert x^{(0)} - \bar x\Vert^2}{(k + 1)^2}, 
%         \end{align*}
%         and the proof is now complete.         
% \end{section}

\section{A Slightly Better Proof For Convergence For FISTA}\label{sec:fista1_proof}
    In this section, we go through a proof that I made personally that doesn't require the momentum sequence $t_k$ for the FISTA algorithm under \hyperref[assumption:1]{assumption \ref*{assumption:1}}. We prepare the following template algorithm: 
    \begin{algorithm}
        \begin{algorithmic}[1]
            \STATE{\textbf{Input:} $x^{(0)}, x^{(-1)}, L, h, g$; 2 initial guesses and stepsize L}
            \STATE{$y^{(0)} = x^{(0)} + \theta_k (x^{(0)} - x^{(-1)})$}
            \FOR{$k = 1, \cdots, N$}
                \STATE{$x^{(k)} = \text{prox}_{h, l^{-1}}(y^{(k)} + l^{-1}\nabla g(y^{(k)})) =: \mathcal Py^{(k)}$}
                \STATE{$y^{(k + 1)} = x^{(k)} + \theta_k(x^{(k)} - x^{(k - 1)})$}
            \ENDFOR
        \end{algorithmic}
        \caption{Template Proximal Gradient Method With Momentum}\label{alg:fista_template}
    \end{algorithm}
    \subsection{Preparations}
        \hyperref[alg:fista_template]{Algorithm \ref*{alg:fista_template}} is a template algorithm without any specific assumptions about $\theta_k$, and it is up to ourselves to find out the best update sequences for the momentum parameters $\theta_k$. To make the proof more intuitive than Beck's proof \cite{paper:FISTA}, we consider the following list of quantities that is more informative: 
        \begin{itemize}
            \item [1.] $v^{(k)} = x^{(k)} - x^{(k -1)}$ is the velocity term. 
            \item [2.] $\bar v^{(k)}= \theta_k v^{(k)}$ is the weighed velocity term. 
            \item [3.] $e^{(k)} := x^{(k)} - \bar x$, where $\bar x \in \arg\min_{x}(f(x))$, where $\bar x$ might not be unique. 
            \item [4.] $\Delta_k := f(x^{(k)}) - f(\bar x)$ which represent the optimality gap at step $k$. 
        \end{itemize}
    \subsection{The Momentum Magic}
        We are looking for the right place to insert momentum in this part. We start by considering the prox 2 point lemma (\hyperref[lemma:prox_two_p]{lemma \ref*{lemma:prox_two_p}}) and substitute $x = x^{(k)}, y = y^{(k + 1)}$ gives: 
        \begin{align*}
            f(x^{(k)}) - f\circ \mathcal Py^{(k + 1)}
            &\ge 
            \frac{L}{2}\Vert \mathcal Py^{(k + 1)} - y^{(k + 1)}\Vert^2 + 
            L \langle y^{(k + 1)} - x^{(k)}, \mathcal P y^{(k + 1)} - y^{(k + 1)}\rangle 
            \\
            [*1]\implies
            2L^{-1} (\Delta_k - \Delta_{k + 1}) 
            &\ge 
            \Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2 + 
            2 \langle x^{(k + 1)} - y^{(k + 1)}, y^{(k + 1)} - x^{(k)}\rangle
            \\
            [*2]\implies
            2L^{-1} (\Delta_k - \Delta_{k + 1})  
            & \ge 
            \textcolor{red}
            {
                \Vert 
                    v^{(k + 1)} - \bar v^{(k)}
                \Vert^2
            }
             + 
            2\langle \textcolor{violet}{v^{(k + 1)} - \bar v^{(k)}}, \bar v^{(k)}\rangle
            \tag{*}
        \end{align*}
        where we make use of the fact that $x^{(k + 1)} = \mathcal P y^{(k + 1)}$ at [$*1$], and using $x^{(k + 1)} - y^{(k + 1)} = x^{(k + 1)} - x^{(k)} - \bar v^{(k)} = v^{(k + 1)} - \bar v^{(k)}$ at [$*2$]. Similarly we can use the prox 2 points lemma (\hyperref[lemma:prox_two_p]{lemma \ref*{lemma:prox_two_p}}) and substitute $x = \bar x, y = y^{(k + 1)}$, giving us: 
        \begin{align*}
            -2L^{-1}\Delta_{k + 1} 
            &\ge 
            \Vert x^{(k + 1)} - y^{(k + 1)}\Vert^2 + 2
            \langle y^{(k + 1)} - \bar x, x^{(k + 1)} - y^{(k + 1)}\rangle
            \\
            -2L^{-1}\Delta_{k + 1} 
            & \ge 
            \textcolor{red}
            {
                \Vert 
                    v^{(k + 1)} - \bar v^{(k)}
                \Vert^2
            } + 
            2\langle  
                \textcolor{violet}{v^{(k + 1)} - \bar v^{(k)}},
                e^{(k)} + \bar v^{(k)}
            \rangle.
            \tag{$\star$}
        \end{align*}
        we make use of the fact that $y^{(k + 1)} = x^{(k)} - \bar v^{(k)}$, then $y^{(k + 1)} - \bar x = x^{(k)} - \bar v^{(k)} - \bar x = e^{(k)} - \bar v^{(k)}$. Without acceleration, we considered the expression $(\star)$. We did some algebra to sum it up like a telescoping series, similar to the proof we did in \hyperref[thm:convergence_non_accelerated]{theorem \ref*{thm:convergence_non_accelerated}}. As an alternative, we consider the linear combination of $(*), (\star)$ such that it leaves $v^{(k)} - \bar v^{(k)}$ inside of the cross term with a multiplier $t_{k + 1}$, let us call it $t_k$ (This is a generic sequence that will contribute to the engineering of the algorithm). As a result $(t_{k + 1}- 1)(*) + (\star)$ with $(t_k - 1)\ge 0$ for all $k$ gives
        \begin{align*}
            & 2L^{-1}((t_{k + 1} - 1)\Delta_k - t_{k + 1}\Delta_{k + 1})
            \\
            & \ge 
            t_{k + 1}
            \textcolor{red}{\Vert v^{(k + 1)} - \bar v^{(k)}\Vert^2} + 
            2\langle 
                \textcolor{violet}{t_{k + 1}(v^{(k + 1)} - \bar v^{(k)})}, e^{(k)} + t_{k + 1} \bar v^{(k)}
            \rangle, 
            \tag{$\star*$}
        \end{align*}
        unfortunately, at the current step, we will not be able to trigger the monotone property and sum it up like in the case without any momentum due to the term $t_{k + 1}$. Instead, we need to consider a new approach. In the next section, we highlight a format for two bounded sequences and reduce the above expression with some conditions on the sequence $t_k$. 
    \subsection{2 Bounded Sequences}
        For the sake of idealization, we may assume that there might exist a way to write $(\star*)$ in the format of $a_k- a_{k + 1}\ge b_{N+ 1} - b_k$. Therefore we introduce the following lemma: 
        \begin{lemma}{2 Bounded Sequences}
            Consider the sequences $a_k, b_k \ge 0$ for $k\in \mathbb N$ with $a_1 + b_1 \le c$. Inductively the two sequences satisfy $a_{k} - a_{k + 1} \le b_{k + 1} - b_k$, which describes a sequence with oscillations bounded by the difference of another sequence. Consider the telescoping sum: 
            \begin{align*}
                a_{k} - a_{k + 1} 
                &\ge b_{k + 1} - b_k \quad \forall k \in \mathbb N
                \\
                \implies
                -\sum_{k = 1}^{N}
                a_{k + 1} - a_k 
                &\ge 
                \sum_{k = 1}^{N} b_{k + 1} - b_k
                \\
                - (a_{N + 1} - a_1) 
                &\ge b_{N + 1} - b_1
                \\
                c\ge a_1 + b_1
                &\ge
                b_{N + 1} + a_{N +1}
                \\
                \implies c \ge a_{N+1}. 
            \end{align*}
        \end{lemma}
        \begin{remark}
            If we make the expression ($\star*$) the same form as the two sequences, then there is a way to restrain the value of $\Delta_k$. Intuitively we are thinking of bounding the changes in the sequence. If the initial $a_1 + b_1$ is bounded by $c$, and $a_k$ has oscillations bounded by changes in $b_k$, then given both $a_k, b_k$ are non-negative, the total amount of changes of $a_k$ will be bounded by the total amount of changes in the sequence $b_k$ as well. 
            \par
            Additionally, we may consider adding a residual term for the sequences $a_{k} - a_{k + 1} \ge b_{k + 1} - b_k + r_k$ with a residual term, then the results $a_{N + 1}$ would be bounded by a larger quantity.
        \end{remark}
    \subsection{Form Matching}
        Our goal is to match the terms in the previous expression $(\star*)$ to the form: $a_k - a_{k + 1}\le b_{k + 1} - b$. To accomplish that, we simplify $(\star*)$ by multiplying both sides by $t_{k + 1}$ (so that we can move the constant to the inside of the norm instead of letting it dangle outside) and we assume it to be a positive quantity larger than one: 
        \begin{align*}
            & \quad 2L^{-1}((t_{k + 1}^2 - t_{k + 1})\Delta_k - t_{k + 1}^2\Delta_{k + 1})
            \\
            & \ge  
            t_{k + 1}^2\Vert v^{(k + 1)} - \bar v^{(k)}\Vert^2 + 
            2\langle t_{k + 1}^2(v^{(k + 1)} - \bar v^{(k)}), e^{(k)} + t_{k + 1} \bar v^{(k)}\rangle
            \\
            &=
            \Vert t_{k + 1} (v^{(k + 1)} - \bar v^{(k)}) \Vert^2 + 
            2\langle t_{k + 1}^2(v^{(k + 1)} - \bar v^{(k)}), e^{(k)} + t_{k + 1}\bar v^{(k)}\rangle
            \\
            &=
            \Vert t_{k+1} v^{(k + 1)} - t_{k + 1}\bar v^{(k)} + e^{(k)} + t_{k + 1}\bar v^{(k)}\Vert^2
            - 
            \Vert e^{(k)} - t_{k + 1} \bar v^{(k)}\Vert^2
            \\
            &=
            \Vert 
                t_{k+1} v^{(k + 1)} + e^{(k)}
            \Vert^2
            - 
            \Vert e^{(k)} - t_{k + 1} \bar v^{(k)}\Vert^2
            \\
            [1]\implies
            & = 
            \Vert t_{k + 1}v^{(k + 1)} + e^{(k)}\Vert^2
            - 
            \Vert v^{(k)} + e^{(k - 1)} + t_{k + 1}\bar v^{(k)} \Vert^2
            \\
            & = 
            \Vert t_{k + 1}v^{(k + 1)} + e^{(k)}\Vert^2
            - 
            \Vert e^{(k - 1)} + (t_{k + 1}\theta_k + 1) v^{(k)} \Vert^2, 
            \tag{$\star \star$}
        \end{align*}
        where at [1], we use the fact that $e^{(k)}= x^{(k)} - \bar x = x^{(k)} - x^{(k - 1)}+ x^{(k - 1)} - \bar x = v^{(k)} - e^{(k)}$ and to match the form, we would need the sequence of $t_k, \theta_k$ to satisfies
        \begin{align*}
            \begin{cases}
                t^2_{k + 1} - t_{k + 1} = t_k^2,
                \\
                t_k = t_{k + 1}\theta_k + 1. 
            \end{cases}
            \tag{$\star **$}
        \end{align*}
        One of the options is the sequence suggested in the FISTA paper, stated as follows: 
        \begin{align*}
            t_k &= \frac{1 + \sqrt{1 + 4t_k^2}}{2}, 
            \\
            \theta_k &= \frac{t_k - 1}{t_{k + 1}}, 
            \tag{$\star \star *$}
        \end{align*}
        moreover, with these properties for the sequences in mind, we can express $(\star\star)$ in the form of:
        \begin{align*}
            \underbrace{2L^{-1}t_k^2\Delta_k}_{a_k} - \underbrace{2L^{-1}t_{k + 1}^2\Delta_{k + 1}}_{a_{k + 1}}
            \ge 
            \underbrace{\Vert t_{k + 1}v^{(k + 1)} + e^{(k)}\Vert^2}_{b_{k + 1}}
            - 
            \underbrace{\Vert e^{(k - 1)} + t_k  v^{(k)} \Vert^2}_{b_{k}}, 
        \end{align*}
        which has $a_k = 2L^{-1}\Delta_{k + 1}$finally, we observe that setting $k = 1$ on $(\star)$ gives: 
        \begin{align*}
            -2L^{-1}  \Delta_1
            & \ge 
            \Vert v^{(1)} - \bar v^{(0)}\Vert^2 + 
            2\langle e^{(0)} - \bar v^{(0)}, v^{(1)} - \bar v^{(0)}\rangle
            \\
            &\ge
            \Vert 
                v^{(1)} - \bar v^{(0)}
                + 
                e^{(0)} - \bar v^{(0)}
            \Vert^2
            - 
            \Vert 
                e^{(0)} - \bar v^{(0)}
            \Vert^2
            \\
            \Vert e^{(0)} - v^{(0)}\Vert^2
            & \ge 
            \Vert v^{(1)} + e^{(0)}\Vert^2 + 2L^{-1}\Delta_1, 
        \end{align*}
        now we let $a_1 = 2L^{-1}\Delta_1$, which implies $t_1 = 1$, and hence we also have $b_1 = \Vert v^{(1)} + e^{(0)}\Vert^2$ with $c = \Vert e^{(0)} - v^{(0)}\Vert^2$, and this completes the base case for using the sequence lemma. Applying the lemma, we obtain 
        \begin{align*}
            a_{N + 1} &\le c
            \\
            2L^{-1}t_{N + 1}^2\Delta_{N + 1} &\le \Vert e^{(0)} - v^{(0)}\Vert^2, 
        \end{align*}
        interestingly, the sequence defined in $t_k$ has a lower bound of $(k + 1)/2$, which will assert convergence for the above expression. We skip the proof for the sequence lower bound here. 

\bibliographystyle{plain}
\bibliography{refs.bib}
\end{document}