\subsection{Proof for Lemma \ref*{lemma:convergence-prep}}
    For better notation we use $T$ to denote the proximal gradient operator $T_L$ appeared in \hyperref[alg:generic_FISTA]{algorithm \ref*{alg:generic_FISTA}}. 
    We need the following lemma to start the proof. 
    See \cite[remark 10.17]{beck_first-order_nodate} for the Proximal Gradient Lemma. 
    \begin{lemma}[Proximal Gradient Lemma]
        With $F = g + h$, where $h$ is convex, closed and proper, with $g$ be $L$-Lipschitz smooth with a constant of $L$, let $y\in \mathbb E$, defining $y^+ = T(y)$ being the proximal gradient step, then for any $x\in \mathbb E$, we have: 
        $$
        \begin{aligned}
        f(x) - f(y^+) \ge \frac{L}{2}\Vert x - y^+\Vert^2 - \frac{L}{2}\Vert x - y\Vert^2 + D_g(x, y),
        \end{aligned}
        $$
        Where $D_g(x, y):= g(x) - g(y) - \langle \nabla g(y), x -y\rangle$ is the Bregman Divergence for the smooth part of the sum: $g$. 
    \end{lemma}
    The following lemma is from Nesterov's new book \cite[thm 2.1.9, (2.1.23)]{nesterov_lectures_2018}. 
    \begin{lemma}[Strong Convexity and the Cute Formula]
        With f be continuous differentiable and $\mu$-strongly convex on $Q\subseteq \mathbb R^n$ , then for all $x, y \in Q$ and $\alpha\in [0, 1]$, we have the equivalent conditions 
        \begin{align}
            \langle \nabla f(x) - \nabla f(y), x - y\rangle &\ge \mu
            \Vert x - y\Vert^2
            \\
            \alpha f(x) + (1 - \alpha) f(y) &\ge
            f(\alpha x + (1 - \alpha)) + 
            \frac{\mu \alpha(1 - \alpha)}{2}
            \Vert x - y\Vert^2. 
        \end{align}
        

    \end{lemma}
    \begin{proof}\label{proof:vfist-convergence-prep}
        With $k\ge 0$, make a sequence $(t_k)_{k\in \mathbb N}$, we consider:
        \begin{itemize}
            \item [1.] $x = t^{-1}_{k + 1}\bar x + (1 - t^{-1}_{k + 1})x^{(k)}, y = y^{(k)}$. 
            \item [2.] $\bar x \in \underset{x}{\text{argmin}}\; F(x)$ and $f(\bar x) = F_{\text{opt}}$. 
        \end{itemize}
        from lemma,
        \begin{align}
            F(x) - F\circ T(y) &\ge 
            \frac{L}{2}\Vert x - T (y)\Vert^2 - \frac{L}{2}\Vert x - y\Vert^2 + D_g(x, y)
            \\
            & \triangleright \text{ strong convexity of g makes }
            D_g(x, y) \ge \frac{\sigma}{2}\Vert y - x\Vert^2
            \\
            & \ge \frac{L}{2}\Vert x - Ty\Vert^2 - \frac{L - \sigma}{2}\Vert x - y\Vert^2. 
        \end{align}\label{eqn:proxgrad_lemma}
        With the substitution into the RHS terms of \hyperref[eqn:proxgrad_lemma]{\ref*{eqn:proxgrad_lemma}}, we can simplify and get
        \begin{align*}
            x - T(y) &=  t^{-1}_{k+1} \bar x + (1 - t^{-1}_{k+1}) x^{(k)} - T y^{(k)}
            \\
            &= t^{-1}_{k+1} \bar x + (1 - t^{-1}_{k+1}) x^{(k)} - x^{(k + 1)}
            \\
            &= t^{-1}_{k + 1}\left(
                \bar x + (t_{k+1} - 1)x^{(k)} - t_{k+1}x^{(k + 1)}
            \right)
            \\
            &= t^{-1}_{k + 1} \left(
                \bar x + t_{k+1} \left(
                    x^{(k)} - x^{(k + 1)}
                \right) - x^{(k)}
            \right)
            \\
            x - y &= t^{-1}_{k+1} \bar x + (1 - t_{k+1}^{-1}) x^{(k)} - y^{(k)}
            \\
            &= t^{-1}_{k + 1}\left(
                \bar x + (t_{k+1} - 1)x^{(k)} - t_{k+1} y^{(k)}
            \right)
            \\
            &= t^{-1}_{k + 1}
            \left(
                \bar x + t_{k+1} \left(
                    x^{(k)} - y^{(k)}
                \right) - x^{(k)}
            \right), 
        \end{align*}
        substituting the above into \hyperref[eqn:proxgrad_lemma]{\ref*{eqn:proxgrad_lemma}} then the RHS yields 
        \begin{align*}
            \frac{L}{2} \left\Vert
            t^{-1}_{k + 1}\left(
             \bar x + t_{k + 1} \left(
                 x^{(k)} - x^{(k + 1)}
             \right) - x^{(k)}
             \right)
            \right\Vert^2 - 
            \frac{(L - \sigma)}{2}
            \left\Vert
                t^{-1}_{k + 1}\left(
                    \bar x + t_{k + 1} \left(
                        x^{(k)} - y^{(k)}
                    \right) - x^{(k)}
                \right)
            \right\Vert^2. 
        \end{align*}
        The LHS of \hyperref[eqn:proxgrad_lemma]{\ref*{eqn:proxgrad_lemma}} can be bounded using strong convexity of $F$.
        \begin{align*}
            F(x) - F\circ T(y)
            &= F(x) - F\left(
                x^{(k + 1)}
            \right) 
            \\
            &= F\left(t_{k + 1}^{-1}x^{(k)} + (1 - t^{-1}_{k + 1})\bar x\right) - 
            F\left(x^{(k + 1)}\right)
            \\
            &\le 
            t_{k + 1}^{-1}F_{\text{opt}}
            + 
            (1 - t_{k + 1}^{-1})F\left(x^{(k)}\right)
            - 
            \frac{\sigma}{2}t^{-1}_k\left(1 - t^{-1}_{k + 1}\right)
            \left\Vert 
                x^{(k)} - \bar x
            \right\Vert^2 
            - F\left(x^{(k + 1)}\right)
            \\
            &= 
            t_{k + 1}^{-1} \left(
                F_{\text{opt}} - F\left(x^{(k)}\right)
            \right) + F\left(x^{(k)}\right) - F\left(x^{(k + 1)} \right)
            -
            \frac{\sigma}{2}t^{-1}_{k + 1}\left(1 - t^{-1}_{k + 1}\right)
            \left\Vert 
                x^{(k)} - \bar x
            \right\Vert^2 
            \\
            & \triangleright  \text{ for better notation make }\delta_k = F\left(x^{(k)}\right) - F_{\text{opt}}
            \\
            &= -t_{k + 1}^{-1}\delta_k + \delta_k  - \delta_{k + 1} 
            -
            \frac{\sigma}{2}t^{-1}_{k + 1}\left(1 - t^{-1}_{k + 1}\right)
            \left\Vert 
                x^{(k)} - \bar x
            \right\Vert^2. 
        \end{align*}
        With the above we present the full form of \hyperref[eqn:proxgrad_lemma]{\ref*{eqn:proxgrad_lemma}} so 
        \begin{align}
            & (1-t_{k + 1}^{-1})\delta_k  - \delta_{k + 1} 
            -
            \frac{\sigma}{2}t^{-1}_{k + 1}\left(1 - t^{-1}_{k + 1}\right)
            \left\Vert 
                x^{(k)} - \bar x
            \right\Vert^2 
            \nonumber
            \\
            &\ge \frac{L}{2} \left\Vert
               t^{-1}_{k + 1}\left(
                \bar x + t_{k + 1} \left(
                    x^{(k)} - x^{(k + 1)}
                \right) - x^{(k)}
                \right)
            \right\Vert^2 - 
            \frac{(L - \sigma)}{2}
            \left\Vert
                t^{-1}_{k + 1}\left(
                    \bar x + t_{k + 1} \left(
                        x^{(k)} - y^{(k)}
                    \right) - x^{(k)}
                \right)
            \right\Vert^2. 
            \nonumber
            \\
            & \triangleright \text{ Multiplying $t_{k + 1}^2$ both sides} \nonumber
            \\
            & (t_{k + 1}^2 - t_{k + 1})\delta_k - t_{k + 1}^2\delta_{k + 1}
            - \frac{\sigma}{2}(t_{k + 1} - 1)
            \left\Vert
                x^{(k)} - \bar x
            \right\Vert^2 
            \nonumber
            \\
            &\ge 
            \frac{L}{2} \left\Vert
                \bar x + t_{k + 1} \left(
                    x^{(k)} - x^{(k + 1)}
                \right) - x^{(k)}
            \right\Vert^2 - 
            \frac{(L - \sigma)}{2}
            \left\Vert
                \bar x + t_{k + 1} \left(
                    x^{(k)} - y^{(k)}
                \right) - x^{(k)}
            \right\Vert^2
            \nonumber
            \\
            & \triangleright \text{re-arranging}, \nonumber
            \\
            & 
            (t_{k + 1}^2 - t_{k + 1})\delta_k - t_{k + 1}^2\delta_{k + 1} 
            \underbrace{
                - 
                \frac{\sigma(t_{k + 1} - 1)}{2}
                \left\Vert
                    x^{(k)} - \bar x
                \right\Vert^2 
                + 
                \frac{L - \sigma}{2}
                \left\Vert
                    \bar x + t_{k + 1}\left( x^{(k)} - y^{(k)}\right) - x^{(k)}
                \right\Vert^2
            }_{-R_k}
            \nonumber
            \\
            &\ge 
            \frac{L}{2}\left\Vert 
                \bar x + t_{k + 1}
                \left(x^{(k)} - x^{(k + 1)}\right) - x^{(k)}
            \right\Vert^2. 
            \label{eqn:full_pg}
        \end{align}
        To make it more manageble we use the quantities established back in the start of \hyperref[sec:fista_strong_convexity]{section \ref*{sec:fista_strong_convexity}} so then 
        \begin{align*}
            &\quad \frac{L - \sigma}{2}
            \left\Vert
                \bar x + t_{k + 1}\left( x^{(k)} - y^{(k)}\right) - x^{(k)}
            \right\Vert^2
            \\
            & \triangleright \text{ Recall from algorithm: }
            \\
            &\qquad 
            \begin{aligned}
                y^{(k)} &= x^{(k)} + \theta_k(x^{(k)} - x^{(k - 1)})
                \\
                y^{(k)} - x^{(k)} &= \theta_k(x^{(k)} - x^{(k - 1)}) = \theta_k s^{(k)} 
            \end{aligned}
            \\
            &=  \frac{L - \sigma}{2}\left\Vert
                \bar x - x^{(k)} - t_{k + 1}\theta_k s^{(k)}
            \right\Vert^2
            \\
            &= \frac{L - \sigma}{2}\left\Vert e^{(k)} + t_{k + 1}\theta_k s^{(k)}\right\Vert^2, 
        \end{align*}
        And observe directly that $u^{(k + 1)}$ is exactly $\bar x + t_{k + 1}(x^{(k)} - x^{(k +1)}) - x^{(k)}$, which is in the norm on the RHS of \hyperref[eqn:full_pg]{\ref*{eqn:full_pg}}. 
        $u^{(k)}$ has representation by $e^{(k)}, x^{(k)}$. 
        \begin{align*}
            u^{(k)} &= \bar x + t_{k}\left(x^{(k - 1)} - x^{(k)} \right) - x^{(k - 1)}
            \\
            &= \bar x + (t_{k} - 1)\left(
                x^{(k - 1)} - x^{(k)}
            \right) + 
            \left(
                x^{(k - 1)} - x^{(k)}
            \right) - x^{(k - 1)}
            \\
            &= \bar x + 
            (t_{k} - 1)\left(x^{(k - 1)} - x^{(k)}\right)
            - x^{(k)}
            \\
            &= - e^{(k)} - (t_{k} - 1)s^{(k)}, 
        \end{align*}
        with these simplifications, we will be able to write down \hyperref[eqn:full_pg]{\ref*{eqn:full_pg}} as 
        \begin{align}
            R_k &=  
            \frac{\sigma(t_{k + 1} - 1)}{2}
            \left\Vert e^{(k)}\right\Vert^2
            - 
            \frac{L - \sigma}{2}\left\Vert e^{(k)} + t_{k + 1}\theta_k s^{(k)}\right\Vert^2
            \\
            t_{k + 1}(t_{k + 1} - 1)\delta_k - R_k
            &\ge 
            t_{k + 1}^2\delta_{k + 1} + \frac{L}{2}\left\Vert u^{(k + 1)}\right\Vert^2. 
        \end{align}
        We are now prepared for deriving a bound on the convergence rate of the algorithm. 
        \begin{align*}
            t_{k + 1}^2\delta_{k + 1}  + 
            \frac{L}{2}\left\Vert
                u^{(k + 1)}
            \right\Vert^2 
            - 
            C_k
            \left\Vert
                u^{(k)}
            \right\Vert^2
            &\le
            t_{k + 1}(t_{k + 1} - 1)\delta_k - R_k
            -
            C_k
            \left\Vert
                u^{(k)}
            \right\Vert^2
            \\
            & \triangleright \text{ With:  $R_k + C_k\left\Vert
                u^{(k)}
            \right\Vert\ge 0$ from \hyperref[lemma:convergence-prep]{lemma \ref*{lemma:convergence-prep}} then, } 
            \\
            t_{k + 1}^2\delta_{k + 1} + \frac{L}{2}\left\Vert
                u^{(k + 1)}
            \right\Vert^2 
            - C_k
            \left\Vert
                u^{(k)}
            \right\Vert^2
            & \le 
            t_{k + 1}(t_{k + 1} - 1)\delta_k
            \\
            &\triangleright \text{ dividing by $t_{k + 1}^2$, re-arrange}
            \\
            \delta_{k + 1}
            &\le 
            (1 - t_{k + 1}^{-1}) \delta_k + \frac{C_k}{t_{k + 1}^{2}}\left\Vert
                u^{(k)}
            \right\Vert^2 -
            \frac{L}{2t^2_{k + 1}}\left\Vert
                u^{(k + 1)}
            \right\Vert^2. 
        \end{align*}
        to have a nice cancellation when unrolling the recurrence, let's use  $\frac{C_k}{t_{k + 1}^2} = \frac{L(1 - t^{-1}_{k + 1})}{2t_{k}^2}$ from \hyperref[lemma:convergence-prep]{lemma \ref*{lemma:convergence-prep}} so
        \begin{align*}
            \delta_{k + 1} &\le 
            (1 - t_{k + 1}^{-1})\delta_k + 
            \frac{L(1 - t_{k + 1}^{-1})}{2t_{k}^2} \left\Vert
                u^{(k)}
            \right\Vert^2 - \frac{L}{2t_{k + 1}^2}\left\Vert u^{(k + 1)} \right\Vert^2
            \\
            \delta_{k + 1} &\le 
            (1 - t_{k + 1}^{-1})\left(
                \delta_k + \frac{L}{2t_{k}^2}\left\Vert
                    u^{(k)}
                \right\Vert^2
            \right) 
            - \frac{L}{2t_{k + 1}^2}\left\Vert u^{(k + 1)}\right\Vert^2
            \\
            & \triangleright \text{ unrolling recursion yield }
            \\
            \delta_{k + 1}
            &\le 
            \left(
                \prod_{i = 0}^{k} \left(
                    1 - t_k^{-1}
                \right)
            \right)\left(
                \delta_0 + \frac{L}{2t_0^2}\left\Vert
                    u^{(0)}
                \right\Vert^2
            \right). 
        \end{align*}
        We are done. 
    \end{proof}

\subsection{Proof for Proposition \ref*{prop:vfista-generic-convergence}}
    \begin{proof}\label{proof:vfista-generic-convergence}
        Observe that condition from \hyperref[lemma:convergence-prep]{lemma \ref*{lemma:convergence-prep}} would mean 
        \begin{align*}
            R_k + C_k\left\Vert
            u^{(k)}
            \right\Vert^2 &\ge 0
            \\
            \frac{\sigma(t_{k + 1} - 1)}{2}
            \left\Vert e^{(k)}\right\Vert^2
            - 
            \frac{L - \sigma}{2}
            \left\Vert e^{(k)} + 
                t_{k + 1}\theta_k s^{(k)}
            \right\Vert^2 
            + 
            \frac{Lt_{k + 1}(t_{k + 1} - 1)}{2t_k^2} 
            \left\Vert u^{(k)}\right\Vert^2 &\ge 0
            \\
            \triangleright 
            \text{ Dividing out by }\frac{L - \sigma}{2}, \text{ recall }u^{(k)} = -e^{(k)} - (t_{k} - 1)s^{(k)}&
            \\
            \frac{\sigma(t_{k +1} - 1)}{L - \sigma}
            \left\Vert e^{(k)}\right\Vert^2
            - 
            \left\Vert e^{(k)} + 
                t_{k + 1}\theta_k s^{(k)}
            \right\Vert^2 
            + 
            \frac{Lt_{k + 1}(t_{k + 1} - 1)}{t^2_k(L - \sigma)}
            \left\Vert 
                e^{(k)} + (t_{k} - 1)s^{(k)}
            \right\Vert^2
            &\ge  0
            \\ 
            \triangleright 
            \text{ Vector quantities }e^{(k)}, s^{(k)} \text{share the same superscript, we may ignore it.}
        \end{align*}
        Expanding the expression would yield quantities $\langle s, e\rangle, \Vert s\Vert^2, \Vert e\Vert^2$, we list them all 
        \begin{align*}
            - \Vert e + t_{k + 1}\theta_k s\Vert^2
            &= - \left(
                \Vert e\Vert^2 + t_{k + 1}^2\theta_k^2 \Vert s\Vert^2 + 
                2\theta_k t_{k + 1}\langle e, s\rangle
            \right)
            \\
            \frac{Lt_{k + 1}(t_{k + 1} - 1)}{t_k^2(L - \sigma)} \Vert 
                e + (t_k - 1)s
            \Vert^2
            &= 
            \frac{Lt_{k + 1}(t_{k + 1} - 1)}{t_k^2(L - \sigma)} 
            \left(
                \Vert e\Vert^2 + (t_k -1)^2 \Vert s\Vert^2 + 2(t_k - 1)\langle e, s\rangle
            \right)
            \\
            \frac{\sigma (t_{k + 1} - 1)}{L - \sigma}
            \Vert e\Vert^2 & 
        \end{align*}
        each of the terms $\Vert e\Vert^2, \Vert s\Vert^2, \langle e, s\rangle$, has their coefficients. These are their coefficients, make $q = \sigma/L$, we simplify and get 
        \begin{align}
            \Vert e\Vert^2 \text{ has: } &
            \quad 
            \frac{\sigma (t_{k + 1} - 1)}{L - \sigma} 
            + 
            \frac{Lt_{k + 1}(t_{k + 1} - 1)}{t_k^2(L - \sigma)} - 1
            \nonumber
            \\
            & = (t_{k + 1} - 1)\left(
                \frac{q}{1 - q} + \frac{t_{k + 1}}{t_k^2(1 - q)}
            \right) - 1
            \nonumber
            \\
            &= 
            \frac{t_{k + 1} - 1}{1 - q}\left(
                q + \frac{t_{k + 1}}{t_k^2}
            \right) - 1
            \nonumber
            \\
            \Vert s\Vert^2 \text{ has: } & 
            \quad 
            \frac{Lt_{k + 1}(t_{k + 1} - 1)}{t_k^2 (L - \sigma)}(t_k - 1)^2
            - t_{k + 1}^2 \theta_k^2
            \nonumber
            \\
            &= 
            \frac{t_{k + 1}(t_{k + 1} - 1)}{t_k^2 (1 - q)}(t_k - 1)^2
            - t_{k + 1}^2\left(
                \frac{t_k - 1}{t_k + 1}
            \right)^2
            \nonumber
            \\
            &= 
            (t_k - 1)^2
            \left(
                \frac{t_{k + 1}(t_{k + 1} - 1)}{t_k^2(1 - q)}
                - 
                \frac{t_{k + 1}^2}{(t_k + 1)^2}
            \right)
            \nonumber
            \\
            \langle s, e\rangle \text{ has: } &
            \quad 
            \frac{2Lt_{k + 1}(t_{k + 1} - 1)}{t_k^2(L - \sigma)}(t_k -1)
            -2\theta_kt_{k + 1}
            \nonumber
            \\
            &= 2(t_k - 1)t_{k + 1}
            \left(
                \frac{t_{k + 1} - 1}{t^2_k(1 - q)}
                -
                \frac{1}{t_k + 1}
            \right), \label{eqn:sequence-cond3}
        \end{align}
        To statisfy the assumption, it would be great to have the coefficients for $\langle s, e\rangle$ to be zero, and the coefficients of $\Vert e\Vert^2, \Vert s\Vert^2$ to be a positive quantities. 
        \par
        For the coefficient of $\langle s, e\rangle$ to be zero, one of the possibility is we would have $t_{k + 1} = \frac{t_k^2(1 - q)}{t_k + 1} + 1$, and $t_k \neq 1$ for all $k\ge 0$. With that we consider the non-negativity conditions on the coefficients for $\Vert e\Vert^2, \Vert s\Vert^2$ so 
        \begin{align}
            \frac{t_{k + 1} - 1}{1 - q} 
            \left(
                1 + \frac{t_{k + 1}}{t_k^2}
            \right)
            -1
            &\ge 0 \quad \triangleright\;  (\ref*{eqn:sequence-cond3}) \iff 
            \frac{t_{k + 1}-1}{1 - q}
            = \frac{t_k^2}{t_k + 1}
            \nonumber
            \\
            \frac{t_k^2}{t_k + 1}\left(
                q + \frac{t_{k + 1}}{t_k^2} 
            \right) 
            &> 1
            \nonumber
            \\
            \triangleright \; \text{Using } t_k &> 1, \forall k\ge0, \text{ from \hyperref[prop:vfista-generic-convergence]{proposition \ref*{prop:vfista-generic-convergence}}}
            \nonumber
            \\
            t_k^2 q + t_{k + 1} &\ge t_k + 1
            \nonumber
            \\
            t_{k + 1} &\ge t_k + 1 - t_k^2 q. \label{eqn:seq-cond1}
        \end{align}
        Similarly the non-negatvity constraints for $\Vert s^{(k)}\Vert^2$ would yield 
        \begin{align*}
            (t_k - 1)^2 
            \left(
                \frac{t_{k + 1}(t_{k + 1} - 1)}{t_k^2(1 - q)}
                -
                \frac{t_{k + 1}^2}{(t_k + 1)^2}
            \right) & 
            \ge 0
            \quad \triangleright \; (\ref*{eqn:sequence-cond3}) 
            \iff \frac{t_{k + 1} - 1}{t_k^2(1 - q)}
            = 
            \frac{1}{t_k + 1}
            \\
            (t_k - 1)^2 \left(
                \frac{t_{k +1}}{t_k + 1} - 
                \frac{t_{k + 1}^2}{(t_k +1)^2} 
            \right)
            &\ge 0 \quad \triangleright \; \text{using } (t_k-1) > 0 
            \\
            \frac{t_{k + 1}}{t_k + 1} &\ge 
            \frac{t_{k + 1}^2}{(t_k + 1)^2}
            \\
            \frac{1}{t_k + 1} & \ge 
            \frac{t_{k + 1}}{(t_k + 1)^2}
            \\
            1 &\ge 
            \frac{t_{k + 1}}{t_k + 1}
            \\
            t_k + 1 &\ge t_{k + 1}. 
        \end{align*}
        Now, under the assumption of $t_k > 1$, the above condition would be redundant since \ref*{eqn:sequence-cond3} has 
        \begin{align*}
            \frac{t_{k + 1} - 1}{t_k^2(1 - q)}
            -
            \frac{1}{t_k + 1} &= 0
            \\
            t_{k + 1} - 1 - 
            \frac{t_k^2(1 - q)}{t_k + 1} &= 0
            \\
            t_{k + 1} &= 1 + 
            \frac{t_k^2(1 - q)}{t_k + 1}
            \\
            & \le 1 + t_k^2/(t_k + 1)
            \\
            &\le 1 + t_k^2/t_k = 1 + t_k. 
        \end{align*}
        We are done. 
        With (\ref*{eqn:seq-cond1}), (\ref*{eqn:sequence-cond3}), and $t_k > 1$ we can use the generic convergence rate of \hyperref[prop:vfista-generic-convergence]{proposition \ref*{prop:vfista-generic-convergence}}
    \end{proof}

\subsection{More Plots and Figure}


